{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8580400,"sourceType":"datasetVersion","datasetId":5131411},{"sourceId":8606225,"sourceType":"datasetVersion","datasetId":5149720}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nwandb_key_label = \"WANDB_KEY\"\nwandb_key= UserSecretsClient().get_secret(wandb_key_label)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:42:42.958359Z","iopub.execute_input":"2024-06-05T15:42:42.959145Z","iopub.status.idle":"2024-06-05T15:42:43.149043Z","shell.execute_reply.started":"2024-06-05T15:42:42.959116Z","shell.execute_reply":"2024-06-05T15:42:43.148301Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import git\ngit.Repo.clone_from('https://github.com/Lumin-Lab/BerCuration', '/kaggle/working/scarf')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:43:35.678740Z","iopub.execute_input":"2024-06-05T15:43:35.679481Z","iopub.status.idle":"2024-06-05T15:43:36.367223Z","shell.execute_reply.started":"2024-06-05T15:43:35.679448Z","shell.execute_reply":"2024-06-05T15:43:36.366248Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<git.repo.base.Repo '/kaggle/working/scarf/.git'>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -r /kaggle/working/scarf/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:00:28.078314Z","iopub.execute_input":"2024-06-05T16:00:28.078708Z","iopub.status.idle":"2024-06-05T16:00:45.251322Z","shell.execute_reply.started":"2024-06-05T16:00:28.078677Z","shell.execute_reply":"2024-06-05T16:00:45.250169Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==2.3.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 1)) (2.3.0)\nRequirement already satisfied: pandas==2.2.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 2)) (2.2.2)\nRequirement already satisfied: wandb==0.17.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 3)) (0.17.0)\nRequirement already satisfied: scikit-learn==1.5.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 4)) (1.5.0)\nRequirement already satisfied: cleanlab==2.6.5 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 5)) (2.6.5)\nCollecting matplotlib==3.9.0 (from -r /kaggle/working/scarf/requirements.txt (line 6))\n  Using cached matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: python-dotenv==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 7)) (1.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2.3.0)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (2023.4)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (4.2.2)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (2.31.0)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (2.3.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (69.0.3)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r /kaggle/working/scarf/requirements.txt (line 4)) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r /kaggle/working/scarf/requirements.txt (line 4)) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r /kaggle/working/scarf/requirements.txt (line 4)) (3.2.0)\nRequirement already satisfied: tqdm>=4.53.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab==2.6.5->-r /kaggle/working/scarf/requirements.txt (line 5)) (4.66.4)\nRequirement already satisfied: termcolor>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab==2.6.5->-r /kaggle/working/scarf/requirements.txt (line 5)) (2.4.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.5.40)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (5.0.1)\nUsing cached matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: matplotlib\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.8.4\n    Uninstalling matplotlib-3.8.4:\n      Successfully uninstalled matplotlib-3.8.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires matplotlib<3.9,>=3.2, but you have matplotlib 3.9.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed matplotlib-3.9.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Train the SCARF Encoder on the Small Train Dataset**","metadata":{}},{"cell_type":"code","source":"import os\n\"\"\"The trained scarf model is saved in \n/kaggle/working/output/scarf.pt if you run the following command:\n\"\"\"\n\ncommand = f\"\"\"\npython /kaggle/working/scarf/run_scarf.py \\\n  --config_dir=/kaggle/working/scarf/configs \\\n  --output_dir=/kaggle/working/output \\\n  --train_data_path=/kaggle/input/small-ber-for-scarf/small_train.csv \\\n  --batch_size=32 \\\n  --epochs=1 \\\n  --lr=3e-5 \\\n  --emb_dim=32 \\\n  --encoder_depth=3 \\\n  --model_name='scarf' \\\n  --corruption_rate=0.3 \\\n  --wandb_project_name='SCARF_Project' \\\n  --wandb_entity='urbancomp' \\\n  --wandb_key='{wandb_key}'\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:00:47.596337Z","iopub.execute_input":"2024-06-05T16:00:47.597334Z","iopub.status.idle":"2024-06-05T16:01:18.884383Z","shell.execute_reply.started":"2024-06-05T16:00:47.597273Z","shell.execute_reply":"2024-06-05T16:01:18.883158Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240605_160052-5h7xj0th\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run SCARF_Project\nwandb: ⭐️ View project at https://wandb.ai/urbancomp/Scarf\nwandb: 🚀 View run at https://wandb.ai/urbancomp/Scarf/runs/5h7xj0th\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/1] - Train Loss: 2.524\nModel saved at /kaggle/working/output/scarf.pt\n","output_type":"stream"},{"name":"stderr","text":"wandb: | 0.002 MB of 0.019 MB uploaded\nwandb: Run history:\nwandb: encoder_train/train_loss ▆▇▇▅▇▅▄▇█▄▇▆█▅▅▆▆▅▆▅▆▃▃▂▃▆▃▃▂▃▃▃▃▂▃▃▃▁▁▁\nwandb: \nwandb: Run summary:\nwandb: encoder_train/train_loss 3.75623\nwandb: \nwandb: 🚀 View run SCARF_Project at: https://wandb.ai/urbancomp/Scarf/runs/5h7xj0th\nwandb: ⭐️ View project at: https://wandb.ai/urbancomp/Scarf\nwandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20240605_160052-5h7xj0th/logs\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Obtain the SCARF embeddings for the Small Train dataset, and save the result**","metadata":{}},{"cell_type":"code","source":"\"\"\"The generated embeddings are saved as a NumPy array in \n/kaggle/working/output/train.npy if you run the following command:\n\"\"\"\nimport os\ncommand = f\"\"\"\npython /kaggle/working/scarf/get_scarf_embedding.py \\\n  --config_dir=/kaggle/working/scarf/configs \\\n  --output_dir=/kaggle/working/output \\\n  --data_path=/kaggle/input/small-ber-for-scarf/small_train.csv \\\n  --batch_size=32 \\\n  --epochs=1 \\\n  --lr=3e-5 \\\n  --emb_dim=32 \\\n  --encoder_depth=3 \\\n  --model_name=\"scarf\" \\\n  --corruption_rate=0.3 \\\n  --embedding_save_name=\"train\"\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:48:51.272980Z","iopub.execute_input":"2024-06-05T15:48:51.273977Z","iopub.status.idle":"2024-06-05T15:48:55.386667Z","shell.execute_reply.started":"2024-06-05T15:48:51.273945Z","shell.execute_reply":"2024-06-05T15:48:55.385600Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/output/scarf.pt\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Obtain the SCARF embeddings for the Small Test dataset, and save the result**","metadata":{}},{"cell_type":"code","source":"\"\"\"The generated embeddings are saved as a NumPy array in \n/kaggle/working/output/test.npy if you run the following command:\n\"\"\"\ncommand = f\"\"\"\npython /kaggle/working/scarf/get_scarf_embedding.py \\\n  --config_dir=/kaggle/working/scarf/configs \\\n  --output_dir=/kaggle/working/output \\\n  --data_path=/kaggle/input/small-ber-for-scarf/small_test.csv \\\n  --batch_size=32 \\\n  --epochs=1 \\\n  --lr=3e-5 \\\n  --emb_dim=32 \\\n  --encoder_depth=3 \\\n  --model_name=\"scarf\" \\\n  --corruption_rate=0.3 \\\n  --embedding_save_name=\"test\"\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:59:18.824757Z","iopub.execute_input":"2024-06-05T15:59:18.825437Z","iopub.status.idle":"2024-06-05T15:59:23.111169Z","shell.execute_reply.started":"2024-06-05T15:59:18.825405Z","shell.execute_reply":"2024-06-05T15:59:23.110266Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/output/scarf.pt\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Load the training and testing embeddings**","metadata":{}},{"cell_type":"code","source":"from cleanlab import Datalab\nimport numpy as np\ntrain_emb = np.load(\"/kaggle/working/output/train.npy\")\ntest_emb = np.load(\"/kaggle/working/output/test.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:49:49.729725Z","iopub.execute_input":"2024-06-05T15:49:49.730071Z","iopub.status.idle":"2024-06-05T15:49:51.795425Z","shell.execute_reply.started":"2024-06-05T15:49:49.730043Z","shell.execute_reply":"2024-06-05T15:49:51.794550Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from cleanlab.outlier import OutOfDistribution\nood = OutOfDistribution()\nood_train_feature_scores = ood.fit_score(features=train_emb)\nood_train_feature_scores = ood.score(features=train_emb)\nood_test_feature_scores = ood.score(features=test_emb)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:49:52.730166Z","iopub.execute_input":"2024-06-05T15:49:52.730730Z","iopub.status.idle":"2024-06-05T15:49:55.412349Z","shell.execute_reply.started":"2024-06-05T15:49:52.730692Z","shell.execute_reply":"2024-06-05T15:49:55.411542Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Fitting OOD estimator based on provided features ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Obtain the indices of outliers in both the training and test datasets with cleanlab**","metadata":{}},{"cell_type":"code","source":"from cleanlab.rank import find_top_issues\ntop = 100\ntop_train_ood_features_idxs = find_top_issues(quality_scores=ood_train_feature_scores, \n                                              top=top)\ntop_test_ood_features_idxs = find_top_issues(quality_scores=ood_test_feature_scores, \n                                              top=top)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:50:05.669499Z","iopub.execute_input":"2024-06-05T15:50:05.669873Z","iopub.status.idle":"2024-06-05T15:50:05.677905Z","shell.execute_reply.started":"2024-06-05T15:50:05.669844Z","shell.execute_reply":"2024-06-05T15:50:05.676874Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Remove the outliers from both the training and test datasets, and save the results**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"/kaggle/input/small-ber-for-scarf/small_train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/small-ber-for-scarf/small_test.csv\")\ntrain_df_new = train_df.drop(top_train_ood_features_idxs, inplace=False)\ntest_df_new = test_df.drop(top_test_ood_features_idxs, inplace=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:50:12.933208Z","iopub.execute_input":"2024-06-05T15:50:12.934077Z","iopub.status.idle":"2024-06-05T15:50:13.296457Z","shell.execute_reply.started":"2024-06-05T15:50:12.934046Z","shell.execute_reply":"2024-06-05T15:50:13.295499Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3652762726.py:2: DtypeWarning: Columns (144,155,161) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(\"/kaggle/input/small-ber-for-scarf/small_train.csv\")\n/tmp/ipykernel_34/3652762726.py:3: DtypeWarning: Columns (144,161) have mixed types. Specify dtype option on import or set low_memory=False.\n  test_df = pd.read_csv(\"/kaggle/input/small-ber-for-scarf/small_test.csv\")\n","output_type":"stream"}]},{"cell_type":"code","source":"import os \nif not os.path.exists(\"/kaggle/working/output/\"):\n    os.mkdir(\"/kaggle/working/output/\")\ntrain_df_new.to_csv(\"/kaggle/working/output/new_small_train.csv\", index=False)\ntest_df_new.to_csv(\"/kaggle/working/output/new_small_test.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:52:50.859731Z","iopub.execute_input":"2024-06-05T15:52:50.860407Z","iopub.status.idle":"2024-06-05T15:52:52.249351Z","shell.execute_reply.started":"2024-06-05T15:52:50.860374Z","shell.execute_reply":"2024-06-05T15:52:52.248345Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Train the MLP classifier on the datasets, following the removal of outliers**","metadata":{}},{"cell_type":"code","source":"\"\"\"The trained mlp classifier will be save in /kaggle/working/output/mlp.pt \nif you run the following command:\n\"\"\"\nimport os\ncommand = f\"\"\"\npython /kaggle/working/scarf/run_mlp.py \\\n  --config_dir \"/kaggle/working/scarf/configs\" \\\n  --output_dir \"/kaggle/working/output\" \\\n  --train_data_path \"/kaggle/working/output/new_small_train.csv\" \\\n  --test_data_path \"/kaggle/working/output/new_small_test.csv\" \\\n  --batch_size 32 \\\n  --epochs 1 \\\n  --lr 0.00003 \\\n  --model_name \"mlp\" \\\n  --wandb_project_name \"test\" \\\n  --wandb_entity \"urbancomp\" \\\n  --wandb_key {wandb_key} \\\n  --hidden_layer 256 128 64 32 16 \\\n  --dropout 0.1\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:53:57.082601Z","iopub.execute_input":"2024-06-05T15:53:57.083321Z","iopub.status.idle":"2024-06-05T15:54:30.262722Z","shell.execute_reply.started":"2024-06-05T15:53:57.083266Z","shell.execute_reply":"2024-06-05T15:54:30.261813Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240605_155401-txodhklo\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run test\nwandb: ⭐️ View project at https://wandb.ai/urbancomp/Scarf-MLP\nwandb: 🚀 View run at https://wandb.ai/urbancomp/Scarf-MLP/runs/txodhklo\n","output_type":"stream"},{"name":"stdout","text":"Model saved at /kaggle/working/output/mlp.pt\nEpoch [1/1] - Train Loss: 2.607, Train Acc: 0.250, Train F1: 0.100, Test Loss: 2.678, Test Acc: 0.109, Test F1: 0.014\nTest Accuracy: 0.109, Test F1: 0.014\n","output_type":"stream"},{"name":"stderr","text":"wandb: / 0.139 MB of 0.139 MB uploaded\nwandb: Run history:\nwandb:      test/A1_acc ▁\nwandb:      test/A2_acc ▁\nwandb:      test/A3_acc ▁\nwandb:      test/B1_acc ▁\nwandb:      test/B2_acc ▁\nwandb:      test/B3_acc ▁\nwandb:      test/C1_acc ▁\nwandb:      test/C2_acc ▁\nwandb:      test/C3_acc ▁\nwandb:      test/D1_acc ▁\nwandb:      test/D2_acc ▁\nwandb:      test/E1_acc ▁\nwandb:      test/E2_acc ▁\nwandb:       test/F_acc ▁\nwandb:       test/G_acc ▁\nwandb:    test/test_acc ▁\nwandb:     test/test_f1 ▁\nwandb:   test/test_loss ▁\nwandb:         train/f1 ▄▃▄▆▂▅▄█▂▃▇▇▃▇▄▅▄▂▇▅▂▄▁▆▄▆▅▄▄▂▁▁▃▇▁▁▂▄▅▃\nwandb:  train/train_acc ▄▂▄▅▂▅▄▇▂▂▅█▂▇▄▅▄▂▇▅▂▄▁▅▄▇▄▄▄▂▁▁▂▇▁▁▂▄▅▂\nwandb: train/train_loss ▇▅▂▄█▆▅▃▅▅▂▃▄▄▄▄▅▅▄▅▄▃▆▁▃▃▄▃▃▅▇▅▆▄▄▅▅▁▄▅\nwandb: \nwandb: Run summary:\nwandb:      test/A1_acc 0.0\nwandb:      test/A2_acc 0.0\nwandb:      test/A3_acc 0.0038\nwandb:      test/B1_acc 0.0\nwandb:      test/B2_acc 0.0\nwandb:      test/B3_acc 0.00273\nwandb:      test/C1_acc 0.0\nwandb:      test/C2_acc 0.0\nwandb:      test/C3_acc 0.0\nwandb:      test/D1_acc 1.0\nwandb:      test/D2_acc 0.0\nwandb:      test/E1_acc 0.0\nwandb:      test/E2_acc 0.0\nwandb:       test/F_acc 0.0\nwandb:       test/G_acc 0.0\nwandb:    test/test_acc 0.10878\nwandb:     test/test_f1 0.01391\nwandb:   test/test_loss 2.67811\nwandb:         train/f1 0.02991\nwandb:  train/train_acc 0.21875\nwandb: train/train_loss 2.65297\nwandb: \nwandb: 🚀 View run test at: https://wandb.ai/urbancomp/Scarf-MLP/runs/txodhklo\nwandb: ⭐️ View project at: https://wandb.ai/urbancomp/Scarf-MLP\nwandb: Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20240605_155401-txodhklo/logs\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]}]}