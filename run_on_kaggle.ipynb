{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8604684,"sourceType":"datasetVersion","datasetId":5148697}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/luminlab/ber-curation?scriptVersionId=184103482\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/luminlab/ber-curation?scriptVersionId=183010840\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/luminlab/ber-curation?scriptVersionId=182786979\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/luminlab/ber-curation?scriptVersionId=182712552\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/luminlab/ber-curation?scriptVersionId=182257992\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"Details of Steps can be found on Google Slides via:¬∂\n\nhttps://docs.google.com/presentation/d/1sb3QkXiYooHqi3p-tkGVUqwqFKd-601_pzU96W1drw0/edit?usp=sharing","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nwandb_key_label = \"WANDB_KEY\"\nwandb_key= UserSecretsClient().get_secret(wandb_key_label)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:36:14.578495Z","iopub.execute_input":"2024-06-17T21:36:14.578891Z","iopub.status.idle":"2024-06-17T21:36:14.947784Z","shell.execute_reply.started":"2024-06-17T21:36:14.578858Z","shell.execute_reply":"2024-06-17T21:36:14.946601Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import git\ngit.Repo.clone_from('https://github.com/Lumin-Lab/BerCuration', '/kaggle/working/scarf')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:36:19.308626Z","iopub.execute_input":"2024-06-17T21:36:19.309015Z","iopub.status.idle":"2024-06-17T21:36:20.975374Z","shell.execute_reply.started":"2024-06-17T21:36:19.308987Z","shell.execute_reply":"2024-06-17T21:36:20.974068Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<git.repo.base.Repo '/kaggle/working/scarf/.git'>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -r /kaggle/working/scarf/requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndef save_csv_file(df, path):\n    dir_name = os.path.dirname(path)\n    if dir_name:\n        if not os.path.exists(dir_name):\n            os.makedirs(dir_name)\n    df.to_csv(path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:36:23.791229Z","iopub.execute_input":"2024-06-17T21:36:23.792209Z","iopub.status.idle":"2024-06-17T21:36:23.799585Z","shell.execute_reply.started":"2024-06-17T21:36:23.79216Z","shell.execute_reply":"2024-06-17T21:36:23.798088Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"raw_data_path = \"/kaggle/input/ber-stratified-samples/BER_stratified_sample.csv\"\nn_splits = 5\noutput_dir = \"/kaggle/working/output\"\nconfig_dir=\"/kaggle/working/scarf/configs\"\nscarf_model_name = \"scarf\"\nmlp_model_name = \"mlp\"\nscarf_batch_size = 32\nscarf_epochs = 15\nscarf_lr = 3e-5\nscarf_emb_dim = 32\nscarf_encoder_depth = 3\nscarf_corruption_rate=0.3\nmax_depth = 5","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:36:47.679427Z","iopub.execute_input":"2024-06-17T21:36:47.679863Z","iopub.status.idle":"2024-06-17T21:36:47.686504Z","shell.execute_reply.started":"2024-06-17T21:36:47.679828Z","shell.execute_reply":"2024-06-17T21:36:47.685357Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nX_raw = pd.read_csv(raw_data_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:36:52.227873Z","iopub.execute_input":"2024-06-17T21:36:52.228284Z","iopub.status.idle":"2024-06-17T21:36:58.751764Z","shell.execute_reply.started":"2024-06-17T21:36:52.22825Z","shell.execute_reply":"2024-06-17T21:36:58.750613Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/797606596.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  X_raw = pd.read_csv(raw_data_path)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport os\nkf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\nfor i, (train_index, test_index) in enumerate(kf.split(X_raw)):\n    save_csv_file(X_raw.iloc[train_index], f\"{output_dir}/split_{i+1}/raw_train.csv\")\n    save_csv_file(X_raw.iloc[test_index], f\"{output_dir}/split_{i+1}/raw_test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:37:03.517813Z","iopub.execute_input":"2024-06-17T21:37:03.518858Z","iopub.status.idle":"2024-06-17T21:38:58.568373Z","shell.execute_reply.started":"2024-06-17T21:37:03.518819Z","shell.execute_reply":"2024-06-17T21:38:58.567307Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\"input: data_path={raw_data_path}\" ,\noutput:{output_dir}/processed.csv \"\"\"\n\ncommand = f\"\"\"\n    python /kaggle/working/scarf/get_processed_dataset.py \\\n      --config_dir={config_dir} \\\n      --output_dir=\"{output_dir}\" \\\n      --data_path={raw_data_path} \\\n      --output_csv_name \"processed\" \\\n      --is_train\n    \"\"\"\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:38:58.570244Z","iopub.execute_input":"2024-06-17T21:38:58.57061Z","iopub.status.idle":"2024-06-17T21:39:36.845223Z","shell.execute_reply.started":"2024-06-17T21:38:58.570578Z","shell.execute_reply":"2024-06-17T21:39:36.844108Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"files_to_copy = [\"column_type_classification.yaml\", \"encoder.joblib\", \"scaler.joblib\", \"train_stats.json\"]\nfor i in range(n_splits):\n    for file_name in files_to_copy:\n        src = f\"{output_dir}/{file_name}\"\n        dest = f\"{output_dir}/split_{i+1}/{file_name}\"\n        os.system(f\"cp {src} {dest}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:39:36.846702Z","iopub.execute_input":"2024-06-17T21:39:36.847068Z","iopub.status.idle":"2024-06-17T21:39:36.920969Z","shell.execute_reply.started":"2024-06-17T21:39:36.847039Z","shell.execute_reply":"2024-06-17T21:39:36.919816Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for i in range(n_splits):\n    \"\"\"input: data_path \"{output_dir}/split_{i+1}/raw_train.csv\" ,\n    output:{output_dir}/split_{i+1}/processed_train.csv \"\"\"\n    command = f\"\"\"\n    python /kaggle/working/scarf/get_processed_dataset.py \\\n      --config_dir \"{config_dir}\" \\\n      --output_dir \"{output_dir}/split_{i+1}\" \\\n      --data_path \"{output_dir}/split_{i+1}/raw_train.csv\" \\\n      --output_csv_name \"processed_train\" \\\n    \"\"\"\n    os.system(command)\n    \"\"\"input: data_path \"{output_dir}/split_{i+1}/raw_test.csv\" ,\n    output:{output_dir}/split_{i+1}/processed_test.csv \"\"\"\n    command = f\"\"\"\n    python /kaggle/working/scarf/get_processed_dataset.py \\\n      --config_dir \"{config_dir}\" \\\n      --output_dir \"{output_dir}/split_{i+1}\" \\\n      --data_path \"{output_dir}/split_{i+1}/raw_test.csv\" \\\n      --output_csv_name \"processed_test\"\n    \"\"\"\n    os.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:39:36.924058Z","iopub.execute_input":"2024-06-17T21:39:36.924431Z","iopub.status.idle":"2024-06-17T21:42:57.111242Z","shell.execute_reply.started":"2024-06-17T21:39:36.924399Z","shell.execute_reply":"2024-06-17T21:42:57.110122Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Train the SCARF Encoder on the Train Dataset**","metadata":{}},{"cell_type":"code","source":"import wandb\nwandb.login(key=wandb_key)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:42:57.112742Z","iopub.execute_input":"2024-06-17T21:42:57.113091Z","iopub.status.idle":"2024-06-17T21:43:01.349938Z","shell.execute_reply.started":"2024-06-17T21:42:57.113063Z","shell.execute_reply":"2024-06-17T21:43:01.348882Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import os\n\"\"\"\nInput: train_data_path=\"{output_dir}/split_{i+1}/processed_train.csv\"\n \nOutput: /kaggle/working/output/split_{split}/scarf.pt  \n\"\"\"\nfor i in range(n_splits):\n    command = f\"\"\"\n    python /kaggle/working/scarf/run_scarf.py\\\n      --config_dir={config_dir} \\\n      --output_dir=\"{output_dir}/split_{i+1}\" \\\n      --train_data_path=\"{output_dir}/split_{i+1}/processed_train.csv\"\\\n      --batch_size={scarf_batch_size} \\\n      --epochs={scarf_epochs} \\\n      --lr={scarf_lr} \\\n      --emb_dim={scarf_emb_dim} \\\n      --encoder_depth={scarf_encoder_depth} \\\n      --model_name=\"{scarf_model_name}\" \\\n      --corruption_rate={scarf_corruption_rate} \\\n      --wandb_project_name='SCARF_Project' \\\n      --wandb_entity='urbancomp' \n    \"\"\"\n\n    os.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T21:43:01.351207Z","iopub.execute_input":"2024-06-17T21:43:01.351719Z","iopub.status.idle":"2024-06-17T22:12:43.095445Z","shell.execute_reply.started":"2024-06-17T21:43:01.35169Z","shell.execute_reply":"2024-06-17T22:12:43.093945Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.17.2 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240617_214305-h5e201tm\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run SCARF_Project\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/urbancomp/Scarf\nwandb: üöÄ View run at https://wandb.ai/urbancomp/Scarf/runs/h5e201tm\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15] - Train Loss: 3.010\nModel saved at /kaggle/working/output/split_1/scarf.pt\nEpoch [2/15] - Train Loss: 2.926\nModel saved at /kaggle/working/output/split_1/scarf.pt\nEpoch [3/15] - Train Loss: 2.866\nModel saved at /kaggle/working/output/split_1/scarf.pt\nEpoch [4/15] - Train Loss: 2.957\nEpoch [5/15] - Train Loss: 2.884\nEpoch [6/15] - Train Loss: 2.919\nEpoch [7/15] - Train Loss: 2.896\nEpoch [8/15] - Train Loss: 2.849\nModel saved at /kaggle/working/output/split_1/scarf.pt\nEpoch [9/15] - Train Loss: 2.942\nEpoch [10/15] - Train Loss: 2.856\nEpoch [11/15] - Train Loss: 2.905\nEpoch [12/15] - Train Loss: 2.846\nModel saved at /kaggle/working/output/split_1/scarf.pt\nEpoch [13/15] - Train Loss: 2.819\nModel saved at /kaggle/working/output/split_1/scarf.pt\nEpoch [14/15] - Train Loss: 2.837\nEpoch [15/15] - Train Loss: 2.808\nModel saved at /kaggle/working/output/split_1/scarf.pt\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.17.2 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240617_214858-44iyo9o4\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run SCARF_Project\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/urbancomp/Scarf\nwandb: üöÄ View run at https://wandb.ai/urbancomp/Scarf/runs/44iyo9o4\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15] - Train Loss: 2.965\nModel saved at /kaggle/working/output/split_2/scarf.pt\nEpoch [2/15] - Train Loss: 2.877\nModel saved at /kaggle/working/output/split_2/scarf.pt\nEpoch [3/15] - Train Loss: 2.858\nModel saved at /kaggle/working/output/split_2/scarf.pt\nEpoch [4/15] - Train Loss: 2.856\nModel saved at /kaggle/working/output/split_2/scarf.pt\nEpoch [5/15] - Train Loss: 2.846\nModel saved at /kaggle/working/output/split_2/scarf.pt\nEpoch [6/15] - Train Loss: 2.843\nModel saved at /kaggle/working/output/split_2/scarf.pt\nEpoch [7/15] - Train Loss: 2.855\nEpoch [8/15] - Train Loss: 2.918\nEpoch [9/15] - Train Loss: 2.777\nModel saved at /kaggle/working/output/split_2/scarf.pt\nEpoch [10/15] - Train Loss: 2.823\nEpoch [11/15] - Train Loss: 2.838\nEpoch [12/15] - Train Loss: 2.910\nEpoch [13/15] - Train Loss: 2.870\nEpoch [14/15] - Train Loss: 2.816\nEpoch [15/15] - Train Loss: 2.763\nModel saved at /kaggle/working/output/split_2/scarf.pt\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.17.2 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240617_215452-ysf9zjn1\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run SCARF_Project\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/urbancomp/Scarf\nwandb: üöÄ View run at https://wandb.ai/urbancomp/Scarf/runs/ysf9zjn1\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15] - Train Loss: 3.031\nModel saved at /kaggle/working/output/split_3/scarf.pt\nEpoch [2/15] - Train Loss: 2.878\nModel saved at /kaggle/working/output/split_3/scarf.pt\nEpoch [3/15] - Train Loss: 2.909\nEpoch [4/15] - Train Loss: 2.838\nModel saved at /kaggle/working/output/split_3/scarf.pt\nEpoch [5/15] - Train Loss: 2.842\nEpoch [6/15] - Train Loss: 2.988\nEpoch [7/15] - Train Loss: 2.850\nEpoch [8/15] - Train Loss: 2.856\nEpoch [9/15] - Train Loss: 2.875\nEpoch [10/15] - Train Loss: 2.844\nEpoch [11/15] - Train Loss: 2.935\nEpoch [12/15] - Train Loss: 2.755\nModel saved at /kaggle/working/output/split_3/scarf.pt\nEpoch [13/15] - Train Loss: 2.852\nEpoch [14/15] - Train Loss: 2.893\nEpoch [15/15] - Train Loss: 2.879\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.17.2 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240617_220045-4abraezd\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run SCARF_Project\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/urbancomp/Scarf\nwandb: üöÄ View run at https://wandb.ai/urbancomp/Scarf/runs/4abraezd\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15] - Train Loss: 2.844\nModel saved at /kaggle/working/output/split_4/scarf.pt\nEpoch [2/15] - Train Loss: 2.919\nEpoch [3/15] - Train Loss: 2.855\nEpoch [4/15] - Train Loss: 2.836\nModel saved at /kaggle/working/output/split_4/scarf.pt\nEpoch [5/15] - Train Loss: 2.852\nEpoch [6/15] - Train Loss: 2.901\nEpoch [7/15] - Train Loss: 2.814\nModel saved at /kaggle/working/output/split_4/scarf.pt\nEpoch [8/15] - Train Loss: 2.811\nModel saved at /kaggle/working/output/split_4/scarf.pt\nEpoch [9/15] - Train Loss: 2.866\nEpoch [10/15] - Train Loss: 2.949\nEpoch [11/15] - Train Loss: 2.870\nEpoch [12/15] - Train Loss: 2.884\nEpoch [13/15] - Train Loss: 2.780\nModel saved at /kaggle/working/output/split_4/scarf.pt\nEpoch [14/15] - Train Loss: 2.934\nEpoch [15/15] - Train Loss: 2.871\n","output_type":"stream"},{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.17.2 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240617_220642-f5r1qugx\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run SCARF_Project\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/urbancomp/Scarf\nwandb: üöÄ View run at https://wandb.ai/urbancomp/Scarf/runs/f5r1qugx\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15] - Train Loss: 2.968\nModel saved at /kaggle/working/output/split_5/scarf.pt\nEpoch [2/15] - Train Loss: 3.054\nEpoch [3/15] - Train Loss: 2.909\nModel saved at /kaggle/working/output/split_5/scarf.pt\nEpoch [4/15] - Train Loss: 2.907\nModel saved at /kaggle/working/output/split_5/scarf.pt\nEpoch [5/15] - Train Loss: 2.858\nModel saved at /kaggle/working/output/split_5/scarf.pt\nEpoch [6/15] - Train Loss: 2.965\nEpoch [7/15] - Train Loss: 2.922\nEpoch [8/15] - Train Loss: 2.949\nEpoch [9/15] - Train Loss: 3.068\nEpoch [10/15] - Train Loss: 2.937\nEpoch [11/15] - Train Loss: 2.923\nEpoch [12/15] - Train Loss: 2.964\nEpoch [13/15] - Train Loss: 2.840\nModel saved at /kaggle/working/output/split_5/scarf.pt\nEpoch [14/15] - Train Loss: 2.916\nEpoch [15/15] - Train Loss: 2.916\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Obtain the SCARF embeddings for different train splits, and save the result**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nInput: data_path=\"{output_dir}/split_{i+1}/processed_train.csv\"\n \nOutput: {output_dir}/split_{i+1}/train.npy\n\"\"\"\nfor i in range(n_splits):\n    command = f\"\"\"\n    python /kaggle/working/scarf/get_scarf_embedding.py \\\n      --config_dir={config_dir} \\\n      --output_dir=\"{output_dir}/split_{i+1}\" \\\n      --data_path=\"{output_dir}/split_{i+1}/processed_train.csv\" \\\n      --batch_size={scarf_batch_size} \\\n      --epochs={scarf_epochs} \\\n      --lr={scarf_lr} \\\n      --emb_dim={scarf_emb_dim} \\\n      --encoder_depth={scarf_encoder_depth} \\\n      --model_name={scarf_model_name} \\\n      --corruption_rate={scarf_corruption_rate} \\\n      --embedding_save_name=\"train\"\n    \"\"\"\n\n    os.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:12:43.09734Z","iopub.execute_input":"2024-06-17T22:12:43.097752Z","iopub.status.idle":"2024-06-17T22:13:26.197459Z","shell.execute_reply.started":"2024-06-17T22:12:43.097705Z","shell.execute_reply":"2024-06-17T22:13:26.196195Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/output/split_1/scarf.pt\nModel loaded from /kaggle/working/output/split_2/scarf.pt\nModel loaded from /kaggle/working/output/split_3/scarf.pt\nModel loaded from /kaggle/working/output/split_4/scarf.pt\nModel loaded from /kaggle/working/output/split_5/scarf.pt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Obtain the SCARF embeddings for different test splits, and save the result**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nInput: data_path=\"{output_dir}/split_{i+1}/processed_test.csv\"\n \nOutput: {output_dir}/split_{i+1}/test.npy\n\"\"\"\nfor i in range(n_splits):\n    command = f\"\"\"\n    python /kaggle/working/scarf/get_scarf_embedding.py\\\n      --config_dir={config_dir} \\\n      --output_dir=\"{output_dir}/split_{i+1}\" \\\n      --data_path=\"{output_dir}/split_{i+1}/processed_test.csv\" \\\n      --batch_size={scarf_batch_size} \\\n      --epochs={scarf_epochs} \\\n      --lr={scarf_lr} \\\n      --emb_dim={scarf_emb_dim} \\\n      --encoder_depth={scarf_encoder_depth} \\\n      --model_name={scarf_model_name} \\\n      --corruption_rate={scarf_corruption_rate} \\\n      --embedding_save_name=\"test\"\n    \"\"\"\n\n    os.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:13:26.19901Z","iopub.execute_input":"2024-06-17T22:13:26.199403Z","iopub.status.idle":"2024-06-17T22:13:51.752864Z","shell.execute_reply.started":"2024-06-17T22:13:26.199364Z","shell.execute_reply":"2024-06-17T22:13:51.751655Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/output/split_1/scarf.pt\nModel loaded from /kaggle/working/output/split_2/scarf.pt\nModel loaded from /kaggle/working/output/split_3/scarf.pt\nModel loaded from /kaggle/working/output/split_4/scarf.pt\nModel loaded from /kaggle/working/output/split_5/scarf.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nInput: data_path=\"{output_dir}/processedt.csv\"\n \nOutput: {output_dir}/split_1/all_emb.npy\n\"\"\"\n\ncommand = f\"\"\"\n    python /kaggle/working/scarf/get_scarf_embedding.py \\\n      --config_dir={config_dir} \\\n      --output_dir=\"{output_dir}/split_1\" \\\n      --data_path=\"{output_dir}/processed.csv\" \\\n      --batch_size={scarf_batch_size} \\\n      --epochs={scarf_epochs} \\\n      --lr={scarf_lr} \\\n      --emb_dim={scarf_emb_dim} \\\n      --encoder_depth={scarf_encoder_depth} \\\n      --model_name={scarf_model_name} \\\n      --corruption_rate={scarf_corruption_rate} \\\n      --embedding_save_name=\"all_emb\"\n    \"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:17:49.18889Z","iopub.execute_input":"2024-06-17T22:17:49.189286Z","iopub.status.idle":"2024-06-17T22:17:58.914098Z","shell.execute_reply.started":"2024-06-17T22:17:49.189248Z","shell.execute_reply":"2024-06-17T22:17:58.912952Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/output/split_1/scarf.pt\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Random Forest**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ndef get_rf(max_depth=max_depth):\n    return RandomForestClassifier(max_depth=max_depth, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:18:27.259532Z","iopub.execute_input":"2024-06-17T22:18:27.259992Z","iopub.status.idle":"2024-06-17T22:18:27.519063Z","shell.execute_reply.started":"2024-06-17T22:18:27.259953Z","shell.execute_reply":"2024-06-17T22:18:27.517917Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Original Data**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nprocessed = pd.read_csv(f\"{output_dir}/processed.csv\")\nall_emb = np.load(f\"{output_dir}/split_1/all_emb.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:18:30.759098Z","iopub.execute_input":"2024-06-17T22:18:30.759828Z","iopub.status.idle":"2024-06-17T22:18:33.15798Z","shell.execute_reply.started":"2024-06-17T22:18:30.75979Z","shell.execute_reply":"2024-06-17T22:18:33.156982Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import cross_val_predict\nfrom cleanlab import Datalab\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:19:21.497565Z","iopub.execute_input":"2024-06-17T22:19:21.497986Z","iopub.status.idle":"2024-06-17T22:19:22.941366Z","shell.execute_reply.started":"2024-06-17T22:19:21.497952Z","shell.execute_reply":"2024-06-17T22:19:22.940264Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_processed = processed.drop(columns=[\"EnergyRating\"])\nlabels = processed['EnergyRating']\nclf = get_rf()\npred_probs = cross_val_predict(\n    clf,\n    X_processed,\n    labels,\n    cv=kf,\n    method=\"predict_proba\",\n)\nKNN = NearestNeighbors(metric='euclidean')\nKNN.fit(X_processed.values)\n\nknn_graph = KNN.kneighbors_graph(mode=\"distance\")\ndata = {\"X\": X_processed.values, \"y\": labels}\n\nlab = Datalab(data, label_name=\"y\")\nlab.find_issues(pred_probs=pred_probs, knn_graph=knn_graph)\n\ndisplay(lab.report())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:19:27.213319Z","iopub.execute_input":"2024-06-17T22:19:27.214063Z","iopub.status.idle":"2024-06-17T22:26:33.640399Z","shell.execute_reply.started":"2024-06-17T22:19:27.214026Z","shell.execute_reply":"2024-06-17T22:26:33.638601Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Finding label issues ...\n","output_type":"stream"},{"name":"stderr","text":"2024-06-17 22:21:30.586010: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-17 22:21:30.586153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-17 22:21:30.724107: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Finding outlier issues ...\nFinding near_duplicate issues ...\nFinding non_iid issues ...\nFinding class_imbalance issues ...\nFinding underperforming_group issues ...\n\nAudit complete. 67266 issues found in the dataset.\nHere is a summary of the different kinds of issues found in the data:\n\n    issue_type  num_issues\n         label       56185\nnear_duplicate        8785\n       outlier        2296\n\nDataset Information: num_examples: 121184, num_classes: 15\n\n\n----------------------- label issues -----------------------\n\nAbout this issue:\n\tExamples whose given label is estimated to be potentially incorrect\n    (e.g. due to annotation error) are flagged as having label issues.\n    \n\nNumber of examples with this issue: 56185\nOverall dataset quality in terms of this issue: 0.5532\n\nExamples representing most severe instances of this issue:\n       is_label_issue  label_score  given_label  predicted_label\n24816            True     0.003259            0                7\n12524            True     0.006361            0                2\n47324            True     0.007696            1                6\n67446            True     0.010001            1                6\n71754            True     0.011046            0                5\n\n\n------------------ near_duplicate issues -------------------\n\nAbout this issue:\n\tA (near) duplicate issue refers to two or more examples in\n    a dataset that are extremely similar to each other, relative\n    to the rest of the dataset.  The examples flagged with this issue\n    may be exactly duplicated, or lie atypically close together when\n    represented as vectors (i.e. feature embeddings).\n    \n\nNumber of examples with this issue: 8785\nOverall dataset quality in terms of this issue: 0.5812\n\nExamples representing most severe instances of this issue:\n       is_near_duplicate_issue  near_duplicate_score                          near_duplicate_sets  distance_to_nearest_neighbor\n12099                     True                   0.0                       [110211, 12058, 46803]                           0.0\n67498                     True                   0.0                                     [104454]                           0.0\n61290                     True                   0.0  [31822, 41350, 44527, 90228, 113967, 58970]                           0.0\n80049                     True                   0.0                                      [30037]                           0.0\n80048                     True                   0.0                 [38004, 60227, 21344, 68517]                           0.0\n\n\n---------------------- outlier issues ----------------------\n\nAbout this issue:\n\tExamples that are very different from the rest of the dataset \n    (i.e. potentially out-of-distribution or rare/anomalous instances).\n    \n\nNumber of examples with this issue: 2296\nOverall dataset quality in terms of this issue: 0.3877\n\nExamples representing most severe instances of this issue:\n       is_outlier_issue  outlier_score\n99966              True   3.949063e-12\n1279               True   1.928371e-06\n54221              True   3.522441e-05\n94225              True   8.496266e-05\n3329               True   1.242950e-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}]},{"cell_type":"code","source":"# Label Issues\nlabel_issues_num =  56185\noutlier_nums = 2296\nduplicates_nums = 8785\n\nissue_results = lab.get_issues(\"label\")\nsorted_issues = issue_results.sort_values(\"label_score\").index\n\nsorted_issues_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_issues, \"Unnamed: 0\"]\n})\nsave_csv_file(sorted_issues_df[:label_issues_num], f\"{output_dir}/random_forest/data/label_issues.csv\")\nprint(len(sorted_issues_df))\n\nprint(\"Label Issues\")\ndisplay(X_raw.iloc[sorted_issues].assign(\n    given_label=labels.iloc[sorted_issues],\n    predicted_label=issue_results[\"predicted_label\"].iloc[sorted_issues]\n).head())\n\n# Outliers\noutlier_results = lab.get_issues(\"outlier\")\nsorted_outliers= outlier_results.sort_values(\"outlier_score\").index\nprint(\"Outliers\")\ndisplay(X_raw.iloc[sorted_outliers].head())\n\nsorted_outliers_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_outliers[:outlier_nums], \"Unnamed: 0\"]\n})\nprint(len(sorted_outliers_df))\nsave_csv_file(sorted_outliers_df, f\"{output_dir}/random_forest/data/outliers.csv\")\n\n\n# Near-duplicate issues\nduplicate_results = lab.get_issues(\"near_duplicate\")\nsorted_duplicates = duplicate_results.sort_values(\"near_duplicate_score\").index\nprint(\"Near-duplicate issues\")\ndisplay(duplicate_results.sort_values(\"near_duplicate_score\").head())\nsorted_duplicates_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_duplicates, \"Unnamed: 0\"]\n})\nprint(len(sorted_duplicates_df))\nsave_csv_file(sorted_duplicates_df[:duplicates_nums], f\"{output_dir}/random_forest/data/duplicates.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:27:04.429463Z","iopub.execute_input":"2024-06-17T22:27:04.430342Z","iopub.status.idle":"2024-06-17T22:27:05.910089Z","shell.execute_reply.started":"2024-06-17T22:27:04.430289Z","shell.execute_reply":"2024-06-17T22:27:05.909024Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"121184\nLabel Issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       Unnamed: 0   CountyName     DwellingTypeDescr  Year_of_Construction  \\\n24816      752940   Co. Galway   Semi-detached house                  2001   \n12524      117187  Co. Donegal        Detached house                  2009   \n47324      648381    Dublin 11     Mid-terrace house                  1976   \n67446      644247   Co. Carlow   Semi-detached house                  1987   \n71754      483281    Dublin 15  End of terrace house                  2018   \n\n          TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n24816  Existing                  A1     -21.61                 65.640   \n12524  Final                     A1       3.89                173.570   \n47324  Existing                  A2      46.82                 87.240   \n67446  Existing                  A2      33.48                 70.000   \n71754  Existing                  A1      15.54                126.567   \n\n       UValueWall  UValueRoof  ...       SA_Code  prob_smarea_error_0corr  \\\n24816        0.55        0.13  ...     067057011                 0.050000   \n12524        0.13        0.11  ...           NaN                      NaN   \n47324        0.42        0.17  ...     268030005                 0.000222   \n67446        0.37        0.20  ...      17045001                 0.050000   \n71754        0.27        0.14  ...  267028004/02                 0.000222   \n\n       prob_smarea_error_100corr    RER  RenewEPnren  RenewEPren    CPC  \\\n24816                   0.050000  1.143      12712.3    15487.50  0.507   \n12524                        NaN    NaN          NaN         NaN -0.188   \n47324                   0.012347  0.692      10529.0     8716.96  0.539   \n67446                   0.050000  0.847      10998.2     9948.62  0.618   \n71754                   0.012347  0.852      12323.4    11348.50  0.062   \n\n         EPC  given_label  predicted_label  \n24816 -0.108            0                7  \n12524  0.022            0                2  \n47324  0.293            1                6  \n67446  0.180            1                6  \n71754  0.106            0                5  \n\n[5 rows x 214 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n      <th>given_label</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24816</th>\n      <td>752940</td>\n      <td>Co. Galway</td>\n      <td>Semi-detached house</td>\n      <td>2001</td>\n      <td>Existing</td>\n      <td>A1</td>\n      <td>-21.61</td>\n      <td>65.640</td>\n      <td>0.55</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>067057011</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>1.143</td>\n      <td>12712.3</td>\n      <td>15487.50</td>\n      <td>0.507</td>\n      <td>-0.108</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>12524</th>\n      <td>117187</td>\n      <td>Co. Donegal</td>\n      <td>Detached house</td>\n      <td>2009</td>\n      <td>Final</td>\n      <td>A1</td>\n      <td>3.89</td>\n      <td>173.570</td>\n      <td>0.13</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.188</td>\n      <td>0.022</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47324</th>\n      <td>648381</td>\n      <td>Dublin 11</td>\n      <td>Mid-terrace house</td>\n      <td>1976</td>\n      <td>Existing</td>\n      <td>A2</td>\n      <td>46.82</td>\n      <td>87.240</td>\n      <td>0.42</td>\n      <td>0.17</td>\n      <td>...</td>\n      <td>268030005</td>\n      <td>0.000222</td>\n      <td>0.012347</td>\n      <td>0.692</td>\n      <td>10529.0</td>\n      <td>8716.96</td>\n      <td>0.539</td>\n      <td>0.293</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>67446</th>\n      <td>644247</td>\n      <td>Co. Carlow</td>\n      <td>Semi-detached house</td>\n      <td>1987</td>\n      <td>Existing</td>\n      <td>A2</td>\n      <td>33.48</td>\n      <td>70.000</td>\n      <td>0.37</td>\n      <td>0.20</td>\n      <td>...</td>\n      <td>17045001</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.847</td>\n      <td>10998.2</td>\n      <td>9948.62</td>\n      <td>0.618</td>\n      <td>0.180</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>71754</th>\n      <td>483281</td>\n      <td>Dublin 15</td>\n      <td>End of terrace house</td>\n      <td>2018</td>\n      <td>Existing</td>\n      <td>A1</td>\n      <td>15.54</td>\n      <td>126.567</td>\n      <td>0.27</td>\n      <td>0.14</td>\n      <td>...</td>\n      <td>267028004/02</td>\n      <td>0.000222</td>\n      <td>0.012347</td>\n      <td>0.852</td>\n      <td>12323.4</td>\n      <td>11348.50</td>\n      <td>0.062</td>\n      <td>0.106</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 214 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"Outliers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       Unnamed: 0   CountyName  DwellingTypeDescr  Year_of_Construction  \\\n99966      912339   Co. Galway     Detached house                  1905   \n1279       654970    Co. Louth     Detached house                  2013   \n54221     1137153    Dublin 18     Detached house                  1944   \n94225         331  Co. Kildare     Detached house                  1943   \n3329       128742    Co. Laois  Mid-terrace house                  1960   \n\n          TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n99966  Existing                  G      842.25                  88.56   \n1279   Provisional               A2      48.08                 984.23   \n54221  Existing                  E1     311.70                 510.65   \n94225  Existing                  G      481.80                  71.00   \n3329   Existing                  G      989.35                 138.82   \n\n       UValueWall  UValueRoof  ...  ThirdWallAgeBandId  ThirdWallTypeId  \\\n99966        1.99        1.44  ...                 2.0              1.0   \n1279         0.16        0.16  ...                 NaN              NaN   \n54221        2.10        2.30  ...                 NaN              NaN   \n94225        2.16        0.13  ...                 NaN              NaN   \n3329         2.10        2.30  ...                 NaN              NaN   \n\n         SA_Code  prob_smarea_error_0corr  prob_smarea_error_100corr  RER  \\\n99966        NaN                      NaN                        NaN  NaN   \n1279         NaN                      NaN                        NaN  NaN   \n54221  267090003                 0.050000                   0.050000  0.0   \n94225   87068001                 0.089325                   0.089325  NaN   \n3329         NaN                      NaN                        NaN  NaN   \n\n       RenewEPnren  RenewEPren    CPC    EPC  \n99966          NaN         NaN    NaN    NaN  \n1279           NaN         NaN  0.335  0.360  \n54221     155887.0         0.0  1.834  1.794  \n94225          NaN         NaN    NaN    NaN  \n3329           NaN         NaN    NaN    NaN  \n\n[5 rows x 212 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>ThirdWallAgeBandId</th>\n      <th>ThirdWallTypeId</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99966</th>\n      <td>912339</td>\n      <td>Co. Galway</td>\n      <td>Detached house</td>\n      <td>1905</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>842.25</td>\n      <td>88.56</td>\n      <td>1.99</td>\n      <td>1.44</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1279</th>\n      <td>654970</td>\n      <td>Co. Louth</td>\n      <td>Detached house</td>\n      <td>2013</td>\n      <td>Provisional</td>\n      <td>A2</td>\n      <td>48.08</td>\n      <td>984.23</td>\n      <td>0.16</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.335</td>\n      <td>0.360</td>\n    </tr>\n    <tr>\n      <th>54221</th>\n      <td>1137153</td>\n      <td>Dublin 18</td>\n      <td>Detached house</td>\n      <td>1944</td>\n      <td>Existing</td>\n      <td>E1</td>\n      <td>311.70</td>\n      <td>510.65</td>\n      <td>2.10</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>267090003</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.0</td>\n      <td>155887.0</td>\n      <td>0.0</td>\n      <td>1.834</td>\n      <td>1.794</td>\n    </tr>\n    <tr>\n      <th>94225</th>\n      <td>331</td>\n      <td>Co. Kildare</td>\n      <td>Detached house</td>\n      <td>1943</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>481.80</td>\n      <td>71.00</td>\n      <td>2.16</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87068001</td>\n      <td>0.089325</td>\n      <td>0.089325</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3329</th>\n      <td>128742</td>\n      <td>Co. Laois</td>\n      <td>Mid-terrace house</td>\n      <td>1960</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>989.35</td>\n      <td>138.82</td>\n      <td>2.10</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 212 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"2296\nNear-duplicate issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       is_near_duplicate_issue  near_duplicate_score  \\\n12099                     True                   0.0   \n67498                     True                   0.0   \n61290                     True                   0.0   \n80049                     True                   0.0   \n80048                     True                   0.0   \n\n                               near_duplicate_sets  \\\n12099                       [110211, 12058, 46803]   \n67498                                     [104454]   \n61290  [31822, 41350, 44527, 90228, 113967, 58970]   \n80049                                      [30037]   \n80048                 [38004, 60227, 21344, 68517]   \n\n       distance_to_nearest_neighbor  \n12099                           0.0  \n67498                           0.0  \n61290                           0.0  \n80049                           0.0  \n80048                           0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_near_duplicate_issue</th>\n      <th>near_duplicate_score</th>\n      <th>near_duplicate_sets</th>\n      <th>distance_to_nearest_neighbor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12099</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[110211, 12058, 46803]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>67498</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[104454]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>61290</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[31822, 41350, 44527, 90228, 113967, 58970]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80049</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[30037]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80048</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[38004, 60227, 21344, 68517]</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"121184\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Before Removal**","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_rf()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_train.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    clf.fit(train_df.drop(columns=[\"EnergyRating\"]), train_df[\"EnergyRating\"])\n    acc = clf.score(test_df.drop(columns=[\"EnergyRating\"]), test_df[\"EnergyRating\"])\n    predict = clf.predict(test_df.drop(columns=[\"EnergyRating\"]))\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\n\n# Save the results to a CSV file\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/random_forest/data/results_after_removal.csv\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:27:13.638942Z","iopub.execute_input":"2024-06-17T22:27:13.639371Z","iopub.status.idle":"2024-06-17T22:28:18.396746Z","shell.execute_reply.started":"2024-06-17T22:27:13.639338Z","shell.execute_reply":"2024-06-17T22:28:18.395438Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Split: 1, Accuracy: 0.36885753187275655, F1 Score: 0.24045867539550603\nSplit: 2, Accuracy: 0.3634938317448529, F1 Score: 0.2362148571977429\nSplit: 3, Accuracy: 0.3649379048562116, F1 Score: 0.24136144933009357\nSplit: 4, Accuracy: 0.3606882039856418, F1 Score: 0.23683361864630365\nSplit: 5, Accuracy: 0.36165208780326785, F1 Score: 0.23467134284219557\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After Removal","metadata":{}},{"cell_type":"code","source":"for i in range(n_splits):\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n    label_issue_index = pd.read_csv(f\"{output_dir}/random_forest/data/label_issues.csv\")\n    train_df_removed = train_df[~train_df[\"Unnamed: 0\"].isin(label_issue_index[\"Unnamed: 0\"])]\n    print(len(train_df_removed), len(train_df_removed)/len(train_df))\n    save_csv_file(train_df_removed, f\"{output_dir}/split_{i+1}/train_removed.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:28:18.398868Z","iopub.execute_input":"2024-06-17T22:28:18.399222Z","iopub.status.idle":"2024-06-17T22:29:28.254611Z","shell.execute_reply.started":"2024-06-17T22:28:18.399191Z","shell.execute_reply":"2024-06-17T22:29:28.253491Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/4162368144.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"52027 0.5366540480881307\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/4162368144.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"51995 0.5363239708294223\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/4162368144.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"51910 0.5354472031109782\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/4162368144.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"52035 0.5367365674028077\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/4162368144.py:2: DtypeWarning: Columns (156,162) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"52029 0.5366691422205718\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(n_splits):\n    command = f\"\"\"\n    python /kaggle/working/scarf/get_processed_dataset.py \\\n      --config_dir {config_dir} \\\n      --output_dir \"{output_dir}/split_{i+1}\" \\\n      --data_path \"{output_dir}/split_{i+1}/train_removed.csv\" \\\n      --output_csv_name \"processed_train_removed\" \\\n    \"\"\"\n    os.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:32:47.117841Z","iopub.execute_input":"2024-06-17T22:32:47.118269Z","iopub.status.idle":"2024-06-17T22:34:19.060297Z","shell.execute_reply.started":"2024-06-17T22:32:47.118235Z","shell.execute_reply":"2024-06-17T22:34:19.059017Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_rf()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_train_removed.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    clf.fit(train_df.drop(columns=[\"EnergyRating\"]), train_df[\"EnergyRating\"])\n    acc = clf.score(test_df.drop(columns=[\"EnergyRating\"]), test_df[\"EnergyRating\"])\n    predict = clf.predict(test_df.drop(columns=[\"EnergyRating\"]))\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\n\n# Save the results to a CSV file\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/random_forest/data/results_after_removal.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:34:19.06277Z","iopub.execute_input":"2024-06-17T22:34:19.063722Z","iopub.status.idle":"2024-06-17T22:34:54.277631Z","shell.execute_reply.started":"2024-06-17T22:34:19.063654Z","shell.execute_reply":"2024-06-17T22:34:54.276279Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Split: 1, Accuracy: 0.3130750505425589, F1 Score: 0.17655629563207229\nSplit: 2, Accuracy: 0.31340512439658375, F1 Score: 0.17825791855950388\nSplit: 3, Accuracy: 0.3128274951520403, F1 Score: 0.17703563003887263\nSplit: 4, Accuracy: 0.3123736436027561, F1 Score: 0.17732593041582576\nSplit: 5, Accuracy: 0.30673378445288, F1 Score: 0.17241522018628241\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Scarf Embedding**","metadata":{}},{"cell_type":"code","source":"\nX_processed = pd.DataFrame(all_emb, columns=[f\"feature_{i+1}\" for i in range(all_emb.shape[1])])\nlabels = processed['EnergyRating']\nclf = get_rf()\npred_probs = cross_val_predict(\n    clf,\n    X_processed,\n    labels,\n    cv=kf,\n    method=\"predict_proba\",\n)\nKNN = NearestNeighbors(metric='euclidean')\nKNN.fit(X_processed.values)\n\nknn_graph = KNN.kneighbors_graph(mode=\"distance\")\ndata = {\"X\": X_processed.values, \"y\": labels}\n\nlab = Datalab(data, label_name=\"y\")\nlab.find_issues(pred_probs=pred_probs, knn_graph=knn_graph)\ndisplay(lab.report())","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:36:00.270438Z","iopub.execute_input":"2024-06-17T22:36:00.271254Z","iopub.status.idle":"2024-06-17T22:44:47.659732Z","shell.execute_reply.started":"2024-06-17T22:36:00.271215Z","shell.execute_reply":"2024-06-17T22:44:47.658302Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Finding label issues ...\nFinding outlier issues ...\nFinding near_duplicate issues ...\nFinding non_iid issues ...\nFinding class_imbalance issues ...\nFinding underperforming_group issues ...\n\nAudit complete. 64678 issues found in the dataset.\nHere is a summary of the different kinds of issues found in the data:\n\n           issue_type  num_issues\n                label       52926\n       near_duplicate        7915\n              outlier        3832\nunderperforming_group           5\n\nDataset Information: num_examples: 121184, num_classes: 15\n\n\n----------------------- label issues -----------------------\n\nAbout this issue:\n\tExamples whose given label is estimated to be potentially incorrect\n    (e.g. due to annotation error) are flagged as having label issues.\n    \n\nNumber of examples with this issue: 52926\nOverall dataset quality in terms of this issue: 0.4681\n\nExamples representing most severe instances of this issue:\n        is_label_issue  label_score  given_label  predicted_label\n24816            False     0.000120            0                7\n111046            True     0.001074            2               10\n96431             True     0.001632           14                6\n31972             True     0.001897            3                9\n104299            True     0.002018            2               10\n\n\n------------------ near_duplicate issues -------------------\n\nAbout this issue:\n\tA (near) duplicate issue refers to two or more examples in\n    a dataset that are extremely similar to each other, relative\n    to the rest of the dataset.  The examples flagged with this issue\n    may be exactly duplicated, or lie atypically close together when\n    represented as vectors (i.e. feature embeddings).\n    \n\nNumber of examples with this issue: 7915\nOverall dataset quality in terms of this issue: 0.5953\n\nExamples representing most severe instances of this issue:\n        is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n33156                      True                   0.0             [37576]                           0.0\n104541                     True                   0.0             [56916]                           0.0\n54683                      True                   0.0      [74172, 67755]                           0.0\n25554                      True                   0.0             [85878]                           0.0\n104553                     True                   0.0      [11315, 53432]                           0.0\n\n\n---------------------- outlier issues ----------------------\n\nAbout this issue:\n\tExamples that are very different from the rest of the dataset \n    (i.e. potentially out-of-distribution or rare/anomalous instances).\n    \n\nNumber of examples with this issue: 3832\nOverall dataset quality in terms of this issue: 0.3798\n\nExamples representing most severe instances of this issue:\n        is_outlier_issue  outlier_score\n99966               True   1.420974e-15\n1279                True   2.254828e-11\n110292              True   6.027487e-09\n94225               True   1.751857e-08\n54221               True   3.311158e-08\n\n\n--------------- underperforming_group issues ---------------\n\nAbout this issue:\n\tAn underperforming group refers to a collection of ‚Äúhard‚Äù examples\n    for which the model predictions are poor. The quality of predictions is\n    computed using the :py:func:`get_self_confidence_for_each_label <cleanlab.rank.get_self_confidence_for_each_label>` function.\n    \n\nNumber of examples with this issue: 5\nOverall dataset quality in terms of this issue: 0.0674\n\nExamples representing most severe instances of this issue:\n        is_underperforming_group_issue  underperforming_group_score\n41400                             True                     0.067434\n107130                            True                     0.067434\n67624                             True                     0.067434\n110246                            True                     0.067434\n62144                             True                     0.067434\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}]},{"cell_type":"code","source":"# Label Issues\nlabel_issues_num =  52164\noutlier_nums = 3752\nduplicates_nums = 7983\n\nissue_results = lab.get_issues(\"label\")\nsorted_issues = issue_results.sort_values(\"label_score\").index\n\nsorted_issues_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_issues, \"Unnamed: 0\"]\n})\nsave_csv_file(sorted_issues_df[:label_issues_num], f\"{output_dir}/random_forest/emb/label_issues.csv\")\nprint(len(sorted_issues_df))\n\nprint(\"Label Issues\")\ndisplay(X_raw.iloc[sorted_issues].assign(\n    given_label=labels.iloc[sorted_issues],\n    predicted_label=issue_results[\"predicted_label\"].iloc[sorted_issues]\n).head())\n\n# Outliers\noutlier_results = lab.get_issues(\"outlier\")\nsorted_outliers= outlier_results.sort_values(\"outlier_score\").index\nprint(\"Outliers\")\ndisplay(X_raw.iloc[sorted_outliers].head())\n\nsorted_outliers_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_outliers[:outlier_nums], \"Unnamed: 0\"]\n})\nprint(len(sorted_outliers_df))\nsave_csv_file(sorted_outliers_df, f\"{output_dir}/random_forest/emb/outliers.csv\")\n\n\n# Near-duplicate issues\nduplicate_results = lab.get_issues(\"near_duplicate\")\nsorted_duplicates = duplicate_results.sort_values(\"near_duplicate_score\").index\nprint(\"Near-duplicate issues\")\ndisplay(duplicate_results.sort_values(\"near_duplicate_score\").head())\nsorted_duplicates_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_duplicates, \"Unnamed: 0\"]\n})\nprint(len(sorted_duplicates_df))\nsave_csv_file(sorted_duplicates_df[:duplicates_nums], f\"{output_dir}/random_forest/emb/duplicates.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:44:47.662631Z","iopub.execute_input":"2024-06-17T22:44:47.663044Z","iopub.status.idle":"2024-06-17T22:44:49.029964Z","shell.execute_reply.started":"2024-06-17T22:44:47.663005Z","shell.execute_reply":"2024-06-17T22:44:49.028579Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"121184\nLabel Issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        Unnamed: 0   CountyName    DwellingTypeDescr  Year_of_Construction  \\\n24816       752940   Co. Galway  Semi-detached house                  2001   \n111046      481391     Dublin 6  Mid-floor apartment                  1900   \n96431        31323   Co. Carlow  Top-floor apartment                  2011   \n31972       484514  Co. Leitrim  Semi-detached house                  1900   \n104299      481398     Dublin 6  Top-floor apartment                  1900   \n\n           TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n24816   Existing                  A1     -21.61                  65.64   \n111046  Existing                  A3      57.66                  17.59   \n96431   Existing                  G      510.16                  69.00   \n31972   Existing                  B1      84.89                 126.82   \n104299  Existing                  A3      57.17                  19.13   \n\n        UValueWall  UValueRoof  ...              SA_Code  \\\n24816         0.55        0.13  ...            067057011   \n111046        0.25        0.00  ...            268132014   \n96431         0.37        0.40  ...             17051005   \n31972         0.31        0.13  ...  117070001/117070002   \n104299        0.25        0.11  ...            268132014   \n\n        prob_smarea_error_0corr  prob_smarea_error_100corr    RER  \\\n24816                  0.050000                   0.050000  1.143   \n111046                 0.050000                   0.050000  0.396   \n96431                  0.000222                   0.012347    NaN   \n31972                  0.050000                   0.050000  0.467   \n104299                 0.050000                   0.050000  0.397   \n\n        RenewEPnren  RenewEPren    CPC    EPC  given_label  predicted_label  \n24816      12712.30    15487.50  0.507 -0.108            0                7  \n111046      1558.85     1021.80  0.172  0.170            2               10  \n96431           NaN         NaN    NaN    NaN           14                6  \n31972      18847.80     9429.72  0.751  0.515            3                9  \n104299      1653.75     1091.02  0.169  0.169            2               10  \n\n[5 rows x 214 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n      <th>given_label</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24816</th>\n      <td>752940</td>\n      <td>Co. Galway</td>\n      <td>Semi-detached house</td>\n      <td>2001</td>\n      <td>Existing</td>\n      <td>A1</td>\n      <td>-21.61</td>\n      <td>65.64</td>\n      <td>0.55</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>067057011</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>1.143</td>\n      <td>12712.30</td>\n      <td>15487.50</td>\n      <td>0.507</td>\n      <td>-0.108</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>111046</th>\n      <td>481391</td>\n      <td>Dublin 6</td>\n      <td>Mid-floor apartment</td>\n      <td>1900</td>\n      <td>Existing</td>\n      <td>A3</td>\n      <td>57.66</td>\n      <td>17.59</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>268132014</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.396</td>\n      <td>1558.85</td>\n      <td>1021.80</td>\n      <td>0.172</td>\n      <td>0.170</td>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>96431</th>\n      <td>31323</td>\n      <td>Co. Carlow</td>\n      <td>Top-floor apartment</td>\n      <td>2011</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>510.16</td>\n      <td>69.00</td>\n      <td>0.37</td>\n      <td>0.40</td>\n      <td>...</td>\n      <td>17051005</td>\n      <td>0.000222</td>\n      <td>0.012347</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>31972</th>\n      <td>484514</td>\n      <td>Co. Leitrim</td>\n      <td>Semi-detached house</td>\n      <td>1900</td>\n      <td>Existing</td>\n      <td>B1</td>\n      <td>84.89</td>\n      <td>126.82</td>\n      <td>0.31</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>117070001/117070002</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.467</td>\n      <td>18847.80</td>\n      <td>9429.72</td>\n      <td>0.751</td>\n      <td>0.515</td>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>104299</th>\n      <td>481398</td>\n      <td>Dublin 6</td>\n      <td>Top-floor apartment</td>\n      <td>1900</td>\n      <td>Existing</td>\n      <td>A3</td>\n      <td>57.17</td>\n      <td>19.13</td>\n      <td>0.25</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>268132014</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.397</td>\n      <td>1653.75</td>\n      <td>1091.02</td>\n      <td>0.169</td>\n      <td>0.169</td>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 214 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"Outliers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        Unnamed: 0   CountyName DwellingTypeDescr  Year_of_Construction  \\\n99966       912339   Co. Galway    Detached house                  1905   \n1279        654970    Co. Louth    Detached house                  2013   \n110292      227162  Co. Wicklow    Detached house                  1970   \n94225          331  Co. Kildare    Detached house                  1943   \n54221      1137153    Dublin 18    Detached house                  1944   \n\n           TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n99966   Existing                  G      842.25                  88.56   \n1279    Provisional               A2      48.08                 984.23   \n110292  Existing                  D2     262.02                 860.31   \n94225   Existing                  G      481.80                  71.00   \n54221   Existing                  E1     311.70                 510.65   \n\n        UValueWall  UValueRoof  ...  ThirdWallAgeBandId  ThirdWallTypeId  \\\n99966         1.99        1.44  ...                 2.0              1.0   \n1279          0.16        0.16  ...                 NaN              NaN   \n110292        2.05        2.30  ...                 NaN              NaN   \n94225         2.16        0.13  ...                 NaN              NaN   \n54221         2.10        2.30  ...                 NaN              NaN   \n\n          SA_Code  prob_smarea_error_0corr  prob_smarea_error_100corr  RER  \\\n99966         NaN                      NaN                        NaN  NaN   \n1279          NaN                      NaN                        NaN  NaN   \n110292        NaN                      NaN                        NaN  NaN   \n94225    87068001                 0.089325                   0.089325  NaN   \n54221   267090003                 0.050000                   0.050000  0.0   \n\n        RenewEPnren  RenewEPren    CPC    EPC  \n99966           NaN         NaN    NaN    NaN  \n1279            NaN         NaN  0.335  0.360  \n110292          NaN         NaN    NaN    NaN  \n94225           NaN         NaN    NaN    NaN  \n54221      155887.0         0.0  1.834  1.794  \n\n[5 rows x 212 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>ThirdWallAgeBandId</th>\n      <th>ThirdWallTypeId</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99966</th>\n      <td>912339</td>\n      <td>Co. Galway</td>\n      <td>Detached house</td>\n      <td>1905</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>842.25</td>\n      <td>88.56</td>\n      <td>1.99</td>\n      <td>1.44</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1279</th>\n      <td>654970</td>\n      <td>Co. Louth</td>\n      <td>Detached house</td>\n      <td>2013</td>\n      <td>Provisional</td>\n      <td>A2</td>\n      <td>48.08</td>\n      <td>984.23</td>\n      <td>0.16</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.335</td>\n      <td>0.360</td>\n    </tr>\n    <tr>\n      <th>110292</th>\n      <td>227162</td>\n      <td>Co. Wicklow</td>\n      <td>Detached house</td>\n      <td>1970</td>\n      <td>Existing</td>\n      <td>D2</td>\n      <td>262.02</td>\n      <td>860.31</td>\n      <td>2.05</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>94225</th>\n      <td>331</td>\n      <td>Co. Kildare</td>\n      <td>Detached house</td>\n      <td>1943</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>481.80</td>\n      <td>71.00</td>\n      <td>2.16</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87068001</td>\n      <td>0.089325</td>\n      <td>0.089325</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>54221</th>\n      <td>1137153</td>\n      <td>Dublin 18</td>\n      <td>Detached house</td>\n      <td>1944</td>\n      <td>Existing</td>\n      <td>E1</td>\n      <td>311.70</td>\n      <td>510.65</td>\n      <td>2.10</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>267090003</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.0</td>\n      <td>155887.0</td>\n      <td>0.0</td>\n      <td>1.834</td>\n      <td>1.794</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 212 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"3752\nNear-duplicate issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n33156                      True                   0.0             [37576]   \n104541                     True                   0.0             [56916]   \n54683                      True                   0.0      [74172, 67755]   \n25554                      True                   0.0             [85878]   \n104553                     True                   0.0      [11315, 53432]   \n\n        distance_to_nearest_neighbor  \n33156                            0.0  \n104541                           0.0  \n54683                            0.0  \n25554                            0.0  \n104553                           0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_near_duplicate_issue</th>\n      <th>near_duplicate_score</th>\n      <th>near_duplicate_sets</th>\n      <th>distance_to_nearest_neighbor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33156</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[37576]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>104541</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[56916]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>54683</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[74172, 67755]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25554</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[85878]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>104553</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[11315, 53432]</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"121184\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Before Removal**","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_rf()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_train.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    train_X = np.load(f\"{output_dir}/split_{i+1}/train.npy\")\n    test_X = np.load(f\"{output_dir}/split_{i+1}/test.npy\")\n    clf.fit(train_X, train_df[\"EnergyRating\"])\n    acc = clf.score(test_X, test_df[\"EnergyRating\"],\n             )\n    predict = clf.predict(test_X)\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\n\n# Save the results to a CSV file\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/random_forest/emb/results_before_removal.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:44:49.031536Z","iopub.execute_input":"2024-06-17T22:44:49.032021Z","iopub.status.idle":"2024-06-17T22:48:10.146137Z","shell.execute_reply.started":"2024-06-17T22:44:49.031978Z","shell.execute_reply":"2024-06-17T22:48:10.144771Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Split: 1, Accuracy: 0.38585633535503566, F1 Score: 0.2823943318526506\nSplit: 2, Accuracy: 0.380080042909601, F1 Score: 0.2815465427112159\nSplit: 3, Accuracy: 0.376531748978834, F1 Score: 0.27809605921699393\nSplit: 4, Accuracy: 0.3766142674423402, F1 Score: 0.2823134228941602\nSplit: 5, Accuracy: 0.3749381085987787, F1 Score: 0.2780300406332188\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**After Removal**","metadata":{}},{"cell_type":"code","source":"original_rating_encoding = {\n    \"A1\": 0,\n    \"A2\": 1,\n    \"A3\": 2,\n    \"B1\": 3,\n    \"B2\": 4,\n    \"B3\": 5,\n    \"C1\": 6,\n    \"C2\": 7,\n    \"C3\": 8,\n    \"D1\": 9,\n    \"D2\": 10,\n    \"E1\": 11,\n    \"E2\": 12,\n    \"F\": 13,\n    \"G\": 14\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:48:10.149592Z","iopub.execute_input":"2024-06-17T22:48:10.150003Z","iopub.status.idle":"2024-06-17T22:48:10.158042Z","shell.execute_reply.started":"2024-06-17T22:48:10.149965Z","shell.execute_reply":"2024-06-17T22:48:10.156888Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"for i in range(n_splits):\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n    train_X = np.load(f\"{output_dir}/split_{i+1}/train.npy\")\n    \n    label_issue_index = pd.read_csv(f\"{output_dir}/random_forest/emb/label_issues.csv\")\n    train_df_removed = train_df[~train_df[\"Unnamed: 0\"].isin(label_issue_index[\"Unnamed: 0\"])]\n    train_X_removed = train_X[train_df_removed.index]\n    train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].str.strip()\n    train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].map(original_rating_encoding)\n    print(len(train_df_removed), len(train_df_removed)/len(train_df))\n    save_csv_file(train_df_removed, f\"{output_dir}/split_{i+1}/train_removed.csv\")\n    np.save(f\"{output_dir}/split_{i+1}/train_removed.npy\", train_X_removed)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:48:10.159593Z","iopub.execute_input":"2024-06-17T22:48:10.160081Z","iopub.status.idle":"2024-06-17T22:49:23.285562Z","shell.execute_reply.started":"2024-06-17T22:48:10.160036Z","shell.execute_reply":"2024-06-17T22:49:23.284346Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2867342498.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n/tmp/ipykernel_33/2867342498.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].str.strip()\n/tmp/ipykernel_33/2867342498.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].map(original_rating_encoding)\n","output_type":"stream"},{"name":"stdout","text":"55107 0.5684239842388109\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2867342498.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n/tmp/ipykernel_33/2867342498.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].str.strip()\n/tmp/ipykernel_33/2867342498.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].map(original_rating_encoding)\n","output_type":"stream"},{"name":"stdout","text":"55311 0.5705282267630767\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2867342498.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n/tmp/ipykernel_33/2867342498.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].str.strip()\n/tmp/ipykernel_33/2867342498.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].map(original_rating_encoding)\n","output_type":"stream"},{"name":"stdout","text":"55129 0.5686509123541729\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2867342498.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n/tmp/ipykernel_33/2867342498.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].str.strip()\n/tmp/ipykernel_33/2867342498.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].map(original_rating_encoding)\n","output_type":"stream"},{"name":"stdout","text":"55312 0.5705385416774114\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2867342498.py:2: DtypeWarning: Columns (156,162) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n/tmp/ipykernel_33/2867342498.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].str.strip()\n/tmp/ipykernel_33/2867342498.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].map(original_rating_encoding)\n","output_type":"stream"},{"name":"stdout","text":"55221 0.5695940091595495\n","output_type":"stream"}]},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_rf()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/train_removed.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    train_X = np.load(f\"{output_dir}/split_{i+1}//train_removed.npy\")\n    test_X = np.load(f\"{output_dir}/split_{i+1}/test.npy\")\n    clf.fit(train_X, train_df[\"EnergyRating\"])\n    acc = clf.score(test_X, test_df[\"EnergyRating\"],\n             )\n    predict = clf.predict(test_X)\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/random_forest/emb/results_after_removal.csv\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:49:23.286874Z","iopub.execute_input":"2024-06-17T22:49:23.287194Z","iopub.status.idle":"2024-06-17T22:51:08.799201Z","shell.execute_reply.started":"2024-06-17T22:49:23.287167Z","shell.execute_reply":"2024-06-17T22:51:08.797955Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/3560689056.py:5: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/train_removed.csv\")\n","output_type":"stream"},{"name":"stdout","text":"Split: 1, Accuracy: 0.3750876758674753, F1 Score: 0.2635707249000939\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/3560689056.py:5: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/train_removed.csv\")\n","output_type":"stream"},{"name":"stdout","text":"Split: 2, Accuracy: 0.37269464042579525, F1 Score: 0.26066285176993925\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/3560689056.py:5: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/train_removed.csv\")\n","output_type":"stream"},{"name":"stdout","text":"Split: 3, Accuracy: 0.3676610141519165, F1 Score: 0.25674041769816314\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/3560689056.py:5: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/train_removed.csv\")\n","output_type":"stream"},{"name":"stdout","text":"Split: 4, Accuracy: 0.36914634649502825, F1 Score: 0.260345964678991\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/3560689056.py:5: DtypeWarning: Columns (156,162) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/train_removed.csv\")\n","output_type":"stream"},{"name":"stdout","text":"Split: 5, Accuracy: 0.36540683281069486, F1 Score: 0.25745068711606794\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**MLP**","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nhidden_layer_sizes = [256 , 128 , 64 , 32 , 16]\nmax_iter = 20\nbatch_size = 32\ndef get_mlp(hidden_layer_sizes=hidden_layer_sizes,\n           max_iter= max_iter,\n           batch_size = batch_size):\n    return MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n                        random_state= 42,\n                        max_iter= max_iter,\n                        batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:51:08.800768Z","iopub.execute_input":"2024-06-17T22:51:08.801196Z","iopub.status.idle":"2024-06-17T22:51:08.820242Z","shell.execute_reply.started":"2024-06-17T22:51:08.801153Z","shell.execute_reply":"2024-06-17T22:51:08.818671Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_processed = processed.drop(columns=[\"EnergyRating\"])\nlabels = processed['EnergyRating']\nclf = get_mlp()\npred_probs = cross_val_predict(\n    clf,\n    X_processed,\n    labels,\n    cv=kf,\n    method=\"predict_proba\",\n)\nKNN = NearestNeighbors(metric='euclidean')\nKNN.fit(X_processed.values)\n\nknn_graph = KNN.kneighbors_graph(mode=\"distance\")\ndata = {\"X\": X_processed.values, \"y\": labels}\n\nlab = Datalab(data, label_name=\"y\")\nlab.find_issues(pred_probs=pred_probs, knn_graph=knn_graph)\n\ndisplay(lab.report())","metadata":{"execution":{"iopub.status.busy":"2024-06-17T22:51:08.822263Z","iopub.execute_input":"2024-06-17T22:51:08.822655Z","iopub.status.idle":"2024-06-17T23:35:34.445535Z","shell.execute_reply.started":"2024-06-17T22:51:08.822622Z","shell.execute_reply":"2024-06-17T23:35:34.443867Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Finding label issues ...\nFinding outlier issues ...\nFinding near_duplicate issues ...\nFinding non_iid issues ...\nFinding class_imbalance issues ...\nFinding underperforming_group issues ...\n\nAudit complete. 46959 issues found in the dataset.\nHere is a summary of the different kinds of issues found in the data:\n\n    issue_type  num_issues\n         label       35878\nnear_duplicate        8785\n       outlier        2296\n\nDataset Information: num_examples: 121184, num_classes: 15\n\n\n----------------------- label issues -----------------------\n\nAbout this issue:\n\tExamples whose given label is estimated to be potentially incorrect\n    (e.g. due to annotation error) are flagged as having label issues.\n    \n\nNumber of examples with this issue: 35878\nOverall dataset quality in terms of this issue: 0.7465\n\nExamples representing most severe instances of this issue:\n        is_label_issue   label_score  given_label  predicted_label\n56543             True  1.548042e-13            2                1\n106655            True  1.554841e-13            2                1\n11116             True  5.396915e-12            9               14\n40824             True  1.152065e-10           13                9\n114825            True  2.903674e-10            0                6\n\n\n------------------ near_duplicate issues -------------------\n\nAbout this issue:\n\tA (near) duplicate issue refers to two or more examples in\n    a dataset that are extremely similar to each other, relative\n    to the rest of the dataset.  The examples flagged with this issue\n    may be exactly duplicated, or lie atypically close together when\n    represented as vectors (i.e. feature embeddings).\n    \n\nNumber of examples with this issue: 8785\nOverall dataset quality in terms of this issue: 0.5812\n\nExamples representing most severe instances of this issue:\n       is_near_duplicate_issue  near_duplicate_score                          near_duplicate_sets  distance_to_nearest_neighbor\n12099                     True                   0.0                       [110211, 12058, 46803]                           0.0\n67498                     True                   0.0                                     [104454]                           0.0\n61290                     True                   0.0  [31822, 41350, 44527, 90228, 113967, 58970]                           0.0\n80049                     True                   0.0                                      [30037]                           0.0\n80048                     True                   0.0                 [38004, 60227, 21344, 68517]                           0.0\n\n\n---------------------- outlier issues ----------------------\n\nAbout this issue:\n\tExamples that are very different from the rest of the dataset \n    (i.e. potentially out-of-distribution or rare/anomalous instances).\n    \n\nNumber of examples with this issue: 2296\nOverall dataset quality in terms of this issue: 0.3877\n\nExamples representing most severe instances of this issue:\n       is_outlier_issue  outlier_score\n99966              True   3.949063e-12\n1279               True   1.928371e-06\n54221              True   3.522441e-05\n94225              True   8.496266e-05\n3329               True   1.242950e-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}]},{"cell_type":"markdown","source":"**Original Data**","metadata":{}},{"cell_type":"code","source":"# Label Issues\nlabel_issues_num =  36939\noutlier_nums = 2296\nduplicates_nums = 8785\n\nissue_results = lab.get_issues(\"label\")\nsorted_issues = issue_results.sort_values(\"label_score\").index\n\nsorted_issues_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_issues, \"Unnamed: 0\"]\n})\nsave_csv_file(sorted_issues_df[:label_issues_num], f\"{output_dir}/mlp/data/label_issues.csv\")\nprint(len(sorted_issues_df))\n\nprint(\"Label Issues\")\ndisplay(X_raw.iloc[sorted_issues].assign(\n    given_label=labels.iloc[sorted_issues],\n    predicted_label=issue_results[\"predicted_label\"].iloc[sorted_issues]\n).head())\n\n# Outliers\noutlier_results = lab.get_issues(\"outlier\")\nsorted_outliers= outlier_results.sort_values(\"outlier_score\").index\nprint(\"Outliers\")\ndisplay(X_raw.iloc[sorted_outliers].head())\n\nsorted_outliers_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_outliers[:outlier_nums], \"Unnamed: 0\"]\n})\nprint(len(sorted_outliers_df))\nsave_csv_file(sorted_outliers_df, f\"{output_dir}/mlp/data/outliers.csv\")\n\n\n# Near-duplicate issues\nduplicate_results = lab.get_issues(\"near_duplicate\")\nsorted_duplicates = duplicate_results.sort_values(\"near_duplicate_score\").index\nprint(\"Near-duplicate issues\")\ndisplay(duplicate_results.sort_values(\"near_duplicate_score\").head())\nsorted_duplicates_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_duplicates, \"Unnamed: 0\"]\n})\nprint(len(sorted_duplicates_df))\nsave_csv_file(sorted_duplicates_df[:duplicates_nums], f\"{output_dir}/mlp/data/duplicates.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T23:35:34.447964Z","iopub.execute_input":"2024-06-17T23:35:34.44854Z","iopub.status.idle":"2024-06-17T23:35:35.857747Z","shell.execute_reply.started":"2024-06-17T23:35:34.448458Z","shell.execute_reply":"2024-06-17T23:35:35.856526Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"121184\nLabel Issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        Unnamed: 0   CountyName  DwellingTypeDescr  Year_of_Construction  \\\n56543       338796    Dublin 15  Mid-terrace house                  2019   \n106655      342190    Dublin 15  Mid-terrace house                  2019   \n11116       781412    Dublin 10  Mid-terrace house                  1940   \n40824       946507  Co. Wexford  Mid-terrace house                  1981   \n114825      761719     Co. Mayo     Detached house                  1900   \n\n           TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n56543   Final                     A3      54.41                 105.28   \n106655  Final                     A3      54.44                 105.04   \n11116   Existing                  D1     246.61                  66.74   \n40824   Existing                  F      405.45                  89.58   \n114825  Existing                  A1      -4.06                  84.54   \n\n        UValueWall  UValueRoof  ...    SA_Code  prob_smarea_error_0corr  \\\n56543         0.18        0.12  ...  268006038             1.868260e-02   \n106655        0.18        0.12  ...  268006038             1.868260e-02   \n11116         2.10        2.30  ...  268057005             5.562300e-07   \n40824         0.95        0.16  ...  247045025             5.562300e-07   \n114825        0.36        0.28  ...  157106003             5.000000e-02   \n\n        prob_smarea_error_100corr    RER  RenewEPnren  RenewEPren    CPC  \\\n56543                    0.018683    NaN          NaN         NaN  0.360   \n106655                   0.018683    NaN          NaN         NaN  0.360   \n11116                    0.002500    NaN          NaN         NaN    NaN   \n40824                    0.002500    NaN          NaN         NaN    NaN   \n114825                   0.050000  1.032          0.0     11020.6 -0.015   \n\n          EPC  given_label  predicted_label  \n56543   0.399            2                1  \n106655  0.399            2                1  \n11116     NaN            9               14  \n40824     NaN           13                9  \n114825 -0.023            0                6  \n\n[5 rows x 214 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n      <th>given_label</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>56543</th>\n      <td>338796</td>\n      <td>Dublin 15</td>\n      <td>Mid-terrace house</td>\n      <td>2019</td>\n      <td>Final</td>\n      <td>A3</td>\n      <td>54.41</td>\n      <td>105.28</td>\n      <td>0.18</td>\n      <td>0.12</td>\n      <td>...</td>\n      <td>268006038</td>\n      <td>1.868260e-02</td>\n      <td>0.018683</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.360</td>\n      <td>0.399</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>106655</th>\n      <td>342190</td>\n      <td>Dublin 15</td>\n      <td>Mid-terrace house</td>\n      <td>2019</td>\n      <td>Final</td>\n      <td>A3</td>\n      <td>54.44</td>\n      <td>105.04</td>\n      <td>0.18</td>\n      <td>0.12</td>\n      <td>...</td>\n      <td>268006038</td>\n      <td>1.868260e-02</td>\n      <td>0.018683</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.360</td>\n      <td>0.399</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11116</th>\n      <td>781412</td>\n      <td>Dublin 10</td>\n      <td>Mid-terrace house</td>\n      <td>1940</td>\n      <td>Existing</td>\n      <td>D1</td>\n      <td>246.61</td>\n      <td>66.74</td>\n      <td>2.10</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>268057005</td>\n      <td>5.562300e-07</td>\n      <td>0.002500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>40824</th>\n      <td>946507</td>\n      <td>Co. Wexford</td>\n      <td>Mid-terrace house</td>\n      <td>1981</td>\n      <td>Existing</td>\n      <td>F</td>\n      <td>405.45</td>\n      <td>89.58</td>\n      <td>0.95</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>247045025</td>\n      <td>5.562300e-07</td>\n      <td>0.002500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>114825</th>\n      <td>761719</td>\n      <td>Co. Mayo</td>\n      <td>Detached house</td>\n      <td>1900</td>\n      <td>Existing</td>\n      <td>A1</td>\n      <td>-4.06</td>\n      <td>84.54</td>\n      <td>0.36</td>\n      <td>0.28</td>\n      <td>...</td>\n      <td>157106003</td>\n      <td>5.000000e-02</td>\n      <td>0.050000</td>\n      <td>1.032</td>\n      <td>0.0</td>\n      <td>11020.6</td>\n      <td>-0.015</td>\n      <td>-0.023</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 214 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"Outliers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       Unnamed: 0   CountyName  DwellingTypeDescr  Year_of_Construction  \\\n99966      912339   Co. Galway     Detached house                  1905   \n1279       654970    Co. Louth     Detached house                  2013   \n54221     1137153    Dublin 18     Detached house                  1944   \n94225         331  Co. Kildare     Detached house                  1943   \n3329       128742    Co. Laois  Mid-terrace house                  1960   \n\n          TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n99966  Existing                  G      842.25                  88.56   \n1279   Provisional               A2      48.08                 984.23   \n54221  Existing                  E1     311.70                 510.65   \n94225  Existing                  G      481.80                  71.00   \n3329   Existing                  G      989.35                 138.82   \n\n       UValueWall  UValueRoof  ...  ThirdWallAgeBandId  ThirdWallTypeId  \\\n99966        1.99        1.44  ...                 2.0              1.0   \n1279         0.16        0.16  ...                 NaN              NaN   \n54221        2.10        2.30  ...                 NaN              NaN   \n94225        2.16        0.13  ...                 NaN              NaN   \n3329         2.10        2.30  ...                 NaN              NaN   \n\n         SA_Code  prob_smarea_error_0corr  prob_smarea_error_100corr  RER  \\\n99966        NaN                      NaN                        NaN  NaN   \n1279         NaN                      NaN                        NaN  NaN   \n54221  267090003                 0.050000                   0.050000  0.0   \n94225   87068001                 0.089325                   0.089325  NaN   \n3329         NaN                      NaN                        NaN  NaN   \n\n       RenewEPnren  RenewEPren    CPC    EPC  \n99966          NaN         NaN    NaN    NaN  \n1279           NaN         NaN  0.335  0.360  \n54221     155887.0         0.0  1.834  1.794  \n94225          NaN         NaN    NaN    NaN  \n3329           NaN         NaN    NaN    NaN  \n\n[5 rows x 212 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>ThirdWallAgeBandId</th>\n      <th>ThirdWallTypeId</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99966</th>\n      <td>912339</td>\n      <td>Co. Galway</td>\n      <td>Detached house</td>\n      <td>1905</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>842.25</td>\n      <td>88.56</td>\n      <td>1.99</td>\n      <td>1.44</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1279</th>\n      <td>654970</td>\n      <td>Co. Louth</td>\n      <td>Detached house</td>\n      <td>2013</td>\n      <td>Provisional</td>\n      <td>A2</td>\n      <td>48.08</td>\n      <td>984.23</td>\n      <td>0.16</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.335</td>\n      <td>0.360</td>\n    </tr>\n    <tr>\n      <th>54221</th>\n      <td>1137153</td>\n      <td>Dublin 18</td>\n      <td>Detached house</td>\n      <td>1944</td>\n      <td>Existing</td>\n      <td>E1</td>\n      <td>311.70</td>\n      <td>510.65</td>\n      <td>2.10</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>267090003</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.0</td>\n      <td>155887.0</td>\n      <td>0.0</td>\n      <td>1.834</td>\n      <td>1.794</td>\n    </tr>\n    <tr>\n      <th>94225</th>\n      <td>331</td>\n      <td>Co. Kildare</td>\n      <td>Detached house</td>\n      <td>1943</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>481.80</td>\n      <td>71.00</td>\n      <td>2.16</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87068001</td>\n      <td>0.089325</td>\n      <td>0.089325</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3329</th>\n      <td>128742</td>\n      <td>Co. Laois</td>\n      <td>Mid-terrace house</td>\n      <td>1960</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>989.35</td>\n      <td>138.82</td>\n      <td>2.10</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 212 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"2296\nNear-duplicate issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       is_near_duplicate_issue  near_duplicate_score  \\\n12099                     True                   0.0   \n67498                     True                   0.0   \n61290                     True                   0.0   \n80049                     True                   0.0   \n80048                     True                   0.0   \n\n                               near_duplicate_sets  \\\n12099                       [110211, 12058, 46803]   \n67498                                     [104454]   \n61290  [31822, 41350, 44527, 90228, 113967, 58970]   \n80049                                      [30037]   \n80048                 [38004, 60227, 21344, 68517]   \n\n       distance_to_nearest_neighbor  \n12099                           0.0  \n67498                           0.0  \n61290                           0.0  \n80049                           0.0  \n80048                           0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_near_duplicate_issue</th>\n      <th>near_duplicate_score</th>\n      <th>near_duplicate_sets</th>\n      <th>distance_to_nearest_neighbor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12099</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[110211, 12058, 46803]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>67498</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[104454]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>61290</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[31822, 41350, 44527, 90228, 113967, 58970]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80049</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[30037]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80048</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[38004, 60227, 21344, 68517]</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"121184\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Before Removal**","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_mlp()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_train.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    clf.fit(train_df.drop(columns=[\"EnergyRating\"]), train_df[\"EnergyRating\"])\n    acc = clf.score(test_df.drop(columns=[\"EnergyRating\"]), test_df[\"EnergyRating\"])\n    predict = clf.predict(test_df.drop(columns=[\"EnergyRating\"]))\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\n\n# Save the results to a CSV file\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/mlp/data/results_before_removal.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T23:35:35.863615Z","iopub.execute_input":"2024-06-17T23:35:35.86401Z","iopub.status.idle":"2024-06-18T00:14:00.54893Z","shell.execute_reply.started":"2024-06-17T23:35:35.863979Z","shell.execute_reply":"2024-06-18T00:14:00.547177Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 1, Accuracy: 0.630936171968478, F1 Score: 0.6099032437785947\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 2, Accuracy: 0.6258612864628461, F1 Score: 0.5953812419495647\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 3, Accuracy: 0.6358047613153444, F1 Score: 0.6001595410154521\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 4, Accuracy: 0.6324627635433429, F1 Score: 0.598625976708746\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 5, Accuracy: 0.6291467238818287, F1 Score: 0.5808560530241175\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**After Removal**","metadata":{}},{"cell_type":"code","source":"for i in range(n_splits):\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n    label_issue_index = pd.read_csv(f\"{output_dir}/mlp/data/label_issues.csv\")\n    train_df_removed = train_df[~train_df[\"Unnamed: 0\"].isin(label_issue_index[\"Unnamed: 0\"])]\n    print(len(train_df_removed), len(train_df_removed)/len(train_df))\n    save_csv_file(train_df_removed, f\"{output_dir}/split_{i+1}/train_removed.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T00:14:00.564639Z","iopub.execute_input":"2024-06-18T00:14:00.567074Z","iopub.status.idle":"2024-06-18T00:15:26.388924Z","shell.execute_reply.started":"2024-06-18T00:14:00.567014Z","shell.execute_reply":"2024-06-18T00:15:26.387452Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2653796351.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"67374 0.6949570383817962\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2653796351.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"67595 0.6972366344497509\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2653796351.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"67148 0.6926258677421684\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2653796351.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"67460 0.6958441210145749\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2653796351.py:2: DtypeWarning: Columns (156,162) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n","output_type":"stream"},{"name":"stdout","text":"67403 0.69524899946363\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(n_splits):\n    command = f\"\"\"\n    python /kaggle/working/scarf/get_processed_dataset.py \\\n      --config_dir {config_dir} \\\n      --output_dir \"{output_dir}/split_{i+1}\" \\\n      --data_path \"{output_dir}/split_{i+1}/train_removed.csv\" \\\n      --output_csv_name \"processed_train_removed\" \\\n    \"\"\"\n    os.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T00:15:26.391812Z","iopub.execute_input":"2024-06-18T00:15:26.392331Z","iopub.status.idle":"2024-06-18T00:17:19.414386Z","shell.execute_reply.started":"2024-06-18T00:15:26.392289Z","shell.execute_reply":"2024-06-18T00:17:19.412755Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_mlp()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_train_removed.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    clf.fit(train_df.drop(columns=[\"EnergyRating\"]), train_df[\"EnergyRating\"])\n    acc = clf.score(test_df.drop(columns=[\"EnergyRating\"]), test_df[\"EnergyRating\"])\n    predict = clf.predict(test_df.drop(columns=[\"EnergyRating\"]))\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\n\n# Save the results to a CSV file\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/mlp/data/results_after_removal.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T00:17:19.417652Z","iopub.execute_input":"2024-06-18T00:17:19.418094Z","iopub.status.idle":"2024-06-18T00:40:06.614287Z","shell.execute_reply.started":"2024-06-18T00:17:19.418061Z","shell.execute_reply":"2024-06-18T00:40:06.612538Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 1, Accuracy: 0.6438503115071997, F1 Score: 0.5925289080138606\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 2, Accuracy: 0.6495853447208813, F1 Score: 0.6060533149750091\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 3, Accuracy: 0.6501217147336716, F1 Score: 0.6039937686841632\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 4, Accuracy: 0.6477699385237446, F1 Score: 0.6114444649265209\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Split: 5, Accuracy: 0.6499422346921935, F1 Score: 0.599780301129709\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Scarf Embedding**","metadata":{}},{"cell_type":"code","source":"\nX_processed = pd.DataFrame(all_emb, columns=[f\"feature_{i+1}\" for i in range(all_emb.shape[1])])\nlabels = processed['EnergyRating']\nclf = get_mlp()\npred_probs = cross_val_predict(\n    clf,\n    X_processed,\n    labels,\n    cv=kf,\n    method=\"predict_proba\",\n)\nKNN = NearestNeighbors(metric='euclidean')\nKNN.fit(X_processed.values)\n\nknn_graph = KNN.kneighbors_graph(mode=\"distance\")\ndata = {\"X\": X_processed.values, \"y\": labels}\n\nlab = Datalab(data, label_name=\"y\")\nlab.find_issues(pred_probs=pred_probs, knn_graph=knn_graph)\ndisplay(lab.report())","metadata":{"execution":{"iopub.status.busy":"2024-06-18T00:40:06.616544Z","iopub.execute_input":"2024-06-18T00:40:06.617459Z","iopub.status.idle":"2024-06-18T01:23:05.71856Z","shell.execute_reply.started":"2024-06-18T00:40:06.61739Z","shell.execute_reply":"2024-06-18T01:23:05.717148Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Finding label issues ...\nFinding outlier issues ...\nFinding near_duplicate issues ...\nFinding non_iid issues ...\nFinding class_imbalance issues ...\nFinding underperforming_group issues ...\n\nAudit complete. 60573 issues found in the dataset.\nHere is a summary of the different kinds of issues found in the data:\n\n    issue_type  num_issues\n         label       48826\nnear_duplicate        7915\n       outlier        3832\n\nDataset Information: num_examples: 121184, num_classes: 15\n\n\n----------------------- label issues -----------------------\n\nAbout this issue:\n\tExamples whose given label is estimated to be potentially incorrect\n    (e.g. due to annotation error) are flagged as having label issues.\n    \n\nNumber of examples with this issue: 48826\nOverall dataset quality in terms of this issue: 0.5702\n\nExamples representing most severe instances of this issue:\n       is_label_issue   label_score  given_label  predicted_label\n24816            True  5.667480e-07            0                9\n97402            True  7.342117e-07            2               11\n95888            True  9.548207e-07           14                6\n75141            True  4.097211e-06            3                9\n49470            True  7.286123e-06           10                5\n\n\n------------------ near_duplicate issues -------------------\n\nAbout this issue:\n\tA (near) duplicate issue refers to two or more examples in\n    a dataset that are extremely similar to each other, relative\n    to the rest of the dataset.  The examples flagged with this issue\n    may be exactly duplicated, or lie atypically close together when\n    represented as vectors (i.e. feature embeddings).\n    \n\nNumber of examples with this issue: 7915\nOverall dataset quality in terms of this issue: 0.5953\n\nExamples representing most severe instances of this issue:\n        is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n33156                      True                   0.0             [37576]                           0.0\n104541                     True                   0.0             [56916]                           0.0\n54683                      True                   0.0      [74172, 67755]                           0.0\n25554                      True                   0.0             [85878]                           0.0\n104553                     True                   0.0      [11315, 53432]                           0.0\n\n\n---------------------- outlier issues ----------------------\n\nAbout this issue:\n\tExamples that are very different from the rest of the dataset \n    (i.e. potentially out-of-distribution or rare/anomalous instances).\n    \n\nNumber of examples with this issue: 3832\nOverall dataset quality in terms of this issue: 0.3798\n\nExamples representing most severe instances of this issue:\n        is_outlier_issue  outlier_score\n99966               True   1.420974e-15\n1279                True   2.254828e-11\n110292              True   6.027487e-09\n94225               True   1.751857e-08\n54221               True   3.311158e-08\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}]},{"cell_type":"code","source":"# Label Issues\nlabel_issues_num =  48890\noutlier_nums =  3752\nduplicates_nums = 7983\n\nissue_results = lab.get_issues(\"label\")\nsorted_issues = issue_results.sort_values(\"label_score\").index\n\nsorted_issues_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_issues, \"Unnamed: 0\"]\n})\nsave_csv_file(sorted_issues_df[:label_issues_num], f\"{output_dir}/mlp/emb/label_issues.csv\")\nprint(len(sorted_issues_df))\n\nprint(\"Label Issues\")\ndisplay(X_raw.iloc[sorted_issues].assign(\n    given_label=labels.iloc[sorted_issues],\n    predicted_label=issue_results[\"predicted_label\"].iloc[sorted_issues]\n).head())\n\n# Outliers\noutlier_results = lab.get_issues(\"outlier\")\nsorted_outliers= outlier_results.sort_values(\"outlier_score\").index\nprint(\"Outliers\")\ndisplay(X_raw.iloc[sorted_outliers].head())\n\nsorted_outliers_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_outliers[:outlier_nums], \"Unnamed: 0\"]\n})\nprint(len(sorted_outliers_df))\nsave_csv_file(sorted_outliers_df, f\"{output_dir}/mlp/emb/outliers.csv\")\n\n\n# Near-duplicate issues\nduplicate_results = lab.get_issues(\"near_duplicate\")\nsorted_duplicates = duplicate_results.sort_values(\"near_duplicate_score\").index\nprint(\"Near-duplicate issues\")\ndisplay(duplicate_results.sort_values(\"near_duplicate_score\").head())\nsorted_duplicates_df = pd.DataFrame({\n    \"Unnamed: 0\": X_raw.loc[sorted_duplicates, \"Unnamed: 0\"]\n})\nprint(len(sorted_duplicates_df))\nsave_csv_file(sorted_duplicates_df[:duplicates_nums], f\"{output_dir}/mlp/emb/duplicates.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T01:23:05.720749Z","iopub.execute_input":"2024-06-18T01:23:05.721135Z","iopub.status.idle":"2024-06-18T01:23:07.158847Z","shell.execute_reply.started":"2024-06-18T01:23:05.721097Z","shell.execute_reply":"2024-06-18T01:23:07.157672Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"121184\nLabel Issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       Unnamed: 0  CountyName       DwellingTypeDescr  Year_of_Construction  \\\n24816      752940  Co. Galway     Semi-detached house                  2001   \n97402     1191541    Dublin 2     Mid-floor apartment                  1993   \n95888      216971    Dublin 9  Ground-floor apartment                  1983   \n75141      544955   Dublin 15     Semi-detached house                  1977   \n49470      260377    Co. Cork          Detached house                  1997   \n\n          TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n24816  Existing                  A1     -21.61                  65.64   \n97402  Existing                  A3      73.17                  65.98   \n95888  Existing                  G      504.80                  37.16   \n75141  Existing                  B1      89.09                  96.48   \n49470  Existing                  D2     294.93                 152.70   \n\n       UValueWall  UValueRoof  ...    SA_Code  prob_smarea_error_0corr  \\\n24816        0.55        0.13  ...  067057011             5.000000e-02   \n97402        0.60        0.00  ...  268140012             2.500000e-03   \n95888        0.60        0.00  ...  268070008             6.929249e-04   \n75141        0.51        0.19  ...  267028025             5.562300e-07   \n49470        0.55        0.40  ...   47227003             5.000000e-02   \n\n       prob_smarea_error_100corr    RER  RenewEPnren  RenewEPren    CPC  \\\n24816                   0.050000  1.143      12712.3    15487.50  0.507   \n97402                   0.002500    NaN          NaN         NaN    NaN   \n95888                   0.012347    NaN          NaN         NaN    NaN   \n75141                   0.002500  0.377      13075.0     5209.68  0.648   \n49470                   0.050000    NaN          NaN         NaN    NaN   \n\n         EPC  given_label  predicted_label  \n24816 -0.108            0                9  \n97402    NaN            2               11  \n95888    NaN           14                6  \n75141  0.594            3                9  \n49470    NaN           10                5  \n\n[5 rows x 214 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n      <th>given_label</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24816</th>\n      <td>752940</td>\n      <td>Co. Galway</td>\n      <td>Semi-detached house</td>\n      <td>2001</td>\n      <td>Existing</td>\n      <td>A1</td>\n      <td>-21.61</td>\n      <td>65.64</td>\n      <td>0.55</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>067057011</td>\n      <td>5.000000e-02</td>\n      <td>0.050000</td>\n      <td>1.143</td>\n      <td>12712.3</td>\n      <td>15487.50</td>\n      <td>0.507</td>\n      <td>-0.108</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>97402</th>\n      <td>1191541</td>\n      <td>Dublin 2</td>\n      <td>Mid-floor apartment</td>\n      <td>1993</td>\n      <td>Existing</td>\n      <td>A3</td>\n      <td>73.17</td>\n      <td>65.98</td>\n      <td>0.60</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>268140012</td>\n      <td>2.500000e-03</td>\n      <td>0.002500</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>95888</th>\n      <td>216971</td>\n      <td>Dublin 9</td>\n      <td>Ground-floor apartment</td>\n      <td>1983</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>504.80</td>\n      <td>37.16</td>\n      <td>0.60</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>268070008</td>\n      <td>6.929249e-04</td>\n      <td>0.012347</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>75141</th>\n      <td>544955</td>\n      <td>Dublin 15</td>\n      <td>Semi-detached house</td>\n      <td>1977</td>\n      <td>Existing</td>\n      <td>B1</td>\n      <td>89.09</td>\n      <td>96.48</td>\n      <td>0.51</td>\n      <td>0.19</td>\n      <td>...</td>\n      <td>267028025</td>\n      <td>5.562300e-07</td>\n      <td>0.002500</td>\n      <td>0.377</td>\n      <td>13075.0</td>\n      <td>5209.68</td>\n      <td>0.648</td>\n      <td>0.594</td>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>49470</th>\n      <td>260377</td>\n      <td>Co. Cork</td>\n      <td>Detached house</td>\n      <td>1997</td>\n      <td>Existing</td>\n      <td>D2</td>\n      <td>294.93</td>\n      <td>152.70</td>\n      <td>0.55</td>\n      <td>0.40</td>\n      <td>...</td>\n      <td>47227003</td>\n      <td>5.000000e-02</td>\n      <td>0.050000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 214 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"Outliers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        Unnamed: 0   CountyName DwellingTypeDescr  Year_of_Construction  \\\n99966       912339   Co. Galway    Detached house                  1905   \n1279        654970    Co. Louth    Detached house                  2013   \n110292      227162  Co. Wicklow    Detached house                  1970   \n94225          331  Co. Kildare    Detached house                  1943   \n54221      1137153    Dublin 18    Detached house                  1944   \n\n           TypeofRating EnergyRating  BerRating  GroundFloorArea(sq m)  \\\n99966   Existing                  G      842.25                  88.56   \n1279    Provisional               A2      48.08                 984.23   \n110292  Existing                  D2     262.02                 860.31   \n94225   Existing                  G      481.80                  71.00   \n54221   Existing                  E1     311.70                 510.65   \n\n        UValueWall  UValueRoof  ...  ThirdWallAgeBandId  ThirdWallTypeId  \\\n99966         1.99        1.44  ...                 2.0              1.0   \n1279          0.16        0.16  ...                 NaN              NaN   \n110292        2.05        2.30  ...                 NaN              NaN   \n94225         2.16        0.13  ...                 NaN              NaN   \n54221         2.10        2.30  ...                 NaN              NaN   \n\n          SA_Code  prob_smarea_error_0corr  prob_smarea_error_100corr  RER  \\\n99966         NaN                      NaN                        NaN  NaN   \n1279          NaN                      NaN                        NaN  NaN   \n110292        NaN                      NaN                        NaN  NaN   \n94225    87068001                 0.089325                   0.089325  NaN   \n54221   267090003                 0.050000                   0.050000  0.0   \n\n        RenewEPnren  RenewEPren    CPC    EPC  \n99966           NaN         NaN    NaN    NaN  \n1279            NaN         NaN  0.335  0.360  \n110292          NaN         NaN    NaN    NaN  \n94225           NaN         NaN    NaN    NaN  \n54221      155887.0         0.0  1.834  1.794  \n\n[5 rows x 212 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>CountyName</th>\n      <th>DwellingTypeDescr</th>\n      <th>Year_of_Construction</th>\n      <th>TypeofRating</th>\n      <th>EnergyRating</th>\n      <th>BerRating</th>\n      <th>GroundFloorArea(sq m)</th>\n      <th>UValueWall</th>\n      <th>UValueRoof</th>\n      <th>...</th>\n      <th>ThirdWallAgeBandId</th>\n      <th>ThirdWallTypeId</th>\n      <th>SA_Code</th>\n      <th>prob_smarea_error_0corr</th>\n      <th>prob_smarea_error_100corr</th>\n      <th>RER</th>\n      <th>RenewEPnren</th>\n      <th>RenewEPren</th>\n      <th>CPC</th>\n      <th>EPC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99966</th>\n      <td>912339</td>\n      <td>Co. Galway</td>\n      <td>Detached house</td>\n      <td>1905</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>842.25</td>\n      <td>88.56</td>\n      <td>1.99</td>\n      <td>1.44</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1279</th>\n      <td>654970</td>\n      <td>Co. Louth</td>\n      <td>Detached house</td>\n      <td>2013</td>\n      <td>Provisional</td>\n      <td>A2</td>\n      <td>48.08</td>\n      <td>984.23</td>\n      <td>0.16</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.335</td>\n      <td>0.360</td>\n    </tr>\n    <tr>\n      <th>110292</th>\n      <td>227162</td>\n      <td>Co. Wicklow</td>\n      <td>Detached house</td>\n      <td>1970</td>\n      <td>Existing</td>\n      <td>D2</td>\n      <td>262.02</td>\n      <td>860.31</td>\n      <td>2.05</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>94225</th>\n      <td>331</td>\n      <td>Co. Kildare</td>\n      <td>Detached house</td>\n      <td>1943</td>\n      <td>Existing</td>\n      <td>G</td>\n      <td>481.80</td>\n      <td>71.00</td>\n      <td>2.16</td>\n      <td>0.13</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87068001</td>\n      <td>0.089325</td>\n      <td>0.089325</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>54221</th>\n      <td>1137153</td>\n      <td>Dublin 18</td>\n      <td>Detached house</td>\n      <td>1944</td>\n      <td>Existing</td>\n      <td>E1</td>\n      <td>311.70</td>\n      <td>510.65</td>\n      <td>2.10</td>\n      <td>2.30</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>267090003</td>\n      <td>0.050000</td>\n      <td>0.050000</td>\n      <td>0.0</td>\n      <td>155887.0</td>\n      <td>0.0</td>\n      <td>1.834</td>\n      <td>1.794</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 212 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"3752\nNear-duplicate issues\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n33156                      True                   0.0             [37576]   \n104541                     True                   0.0             [56916]   \n54683                      True                   0.0      [74172, 67755]   \n25554                      True                   0.0             [85878]   \n104553                     True                   0.0      [11315, 53432]   \n\n        distance_to_nearest_neighbor  \n33156                            0.0  \n104541                           0.0  \n54683                            0.0  \n25554                            0.0  \n104553                           0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_near_duplicate_issue</th>\n      <th>near_duplicate_score</th>\n      <th>near_duplicate_sets</th>\n      <th>distance_to_nearest_neighbor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33156</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[37576]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>104541</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[56916]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>54683</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[74172, 67755]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25554</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[85878]</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>104553</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>[11315, 53432]</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"121184\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Before Removal**","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_mlp()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_train.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    train_X = np.load(f\"{output_dir}/split_{i+1}/train.npy\")\n    test_X = np.load(f\"{output_dir}/split_{i+1}/test.npy\")\n    clf.fit(train_X, train_df[\"EnergyRating\"])\n    acc = clf.score(test_X, test_df[\"EnergyRating\"],\n             )\n    predict = clf.predict(test_X)\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\n\n# Save the results to a CSV file\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/mlp/emb/results_before_removal.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After Removal**","metadata":{}},{"cell_type":"code","source":"for i in range(n_splits):\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/raw_train.csv\")\n    train_X = np.load(f\"{output_dir}/split_{i+1}/train.npy\")\n    \n    label_issue_index = pd.read_csv(f\"{output_dir}/mlp/emb/label_issues.csv\")\n    train_df_removed = train_df[~train_df[\"Unnamed: 0\"].isin(label_issue_index[\"Unnamed: 0\"])]\n    train_X_removed = train_X[train_df_removed.index]\n    train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].str.strip()\n    train_df_removed['EnergyRating'] = train_df_removed['EnergyRating'].map(original_rating_encoding)\n    print(len(train_df_removed), len(train_df_removed)/len(train_df))\n    save_csv_file(train_df_removed, f\"{output_dir}/split_{i+1}/train_removed.csv\")\n    np.save(f\"{output_dir}/split_{i+1}/train_removed.npy\", train_X_removed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\n\nfor i in range(n_splits):\n    clf = get_mlp()\n    train_df = pd.read_csv(f\"{output_dir}/split_{i+1}/train_removed.csv\")\n    test_df = pd.read_csv(f\"{output_dir}/split_{i+1}/processed_test.csv\")\n    train_X = np.load(f\"{output_dir}/split_{i+1}//train_removed.npy\")\n    test_X = np.load(f\"{output_dir}/split_{i+1}/test.npy\")\n    clf.fit(train_X, train_df[\"EnergyRating\"])\n    acc = clf.score(test_X, test_df[\"EnergyRating\"],\n             )\n    predict = clf.predict(test_X)\n    f1 = f1_score(test_df[\"EnergyRating\"], predict, average='macro')\n    print(f\"Split: {i+1}, Accuracy: {acc}, F1 Score: {f1}\")\n    results.append({\"Split\": i+1, \"Accuracy\": acc, \"F1 Score\": f1})\nresults_df = pd.DataFrame(results)\nsave_csv_file(results_df, f\"{output_dir}/mlp/emb/results_after_removal.csv\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef compare_results(data_before, data_after, emb_before, emb_after, title):\n    fig, ax = plt.subplots(2,1, figsize=(8, 8), sharex=True)\n    fig.suptitle(title)\n\n    # Plot Accuracy comparison\n    bar_width = 0.2\n    splits = data_before['Split']\n\n    ax[0].bar(splits - 1.5 * bar_width, data_before['Accuracy'], width=bar_width, label='Data Before Removal')\n    ax[0].bar(splits - 0.5 * bar_width, data_after['Accuracy'], width=bar_width, label='Data After Removal')\n    ax[0].bar(splits + 0.5 * bar_width, emb_before['Accuracy'], width=bar_width, label='Emb Before Removal')\n    ax[0].bar(splits + 1.5 * bar_width, emb_after['Accuracy'], width=bar_width, label='Emb After Removal')\n    ax[0].set_title('Accuracy Comparison')\n    ax[0].set_ylabel('Accuracy')\n\n    # Plot F1 Score comparison\n    ax[1].bar(splits - 1.5 * bar_width, data_before['F1 Score'], width=bar_width, label='Data Before Removal')\n    ax[1].bar(splits - 0.5 * bar_width, data_after['F1 Score'], width=bar_width, label='Data After Removal')\n    ax[1].bar(splits + 0.5 * bar_width, emb_before['F1 Score'], width=bar_width, label='Emb Before Removal')\n    ax[1].bar(splits + 1.5 * bar_width, emb_after['F1 Score'], width=bar_width, label='Emb After Removal')\n    ax[1].set_title('F1 Score Comparison')\n    ax[1].set_xlabel('Split')\n    ax[1].set_ylabel('F1 Score')\n\n    # plt.subplots_adjust(right=0.8)\n\n    # Create a single legend outside of the plot, on the right\n    handles, labels = ax[0].get_legend_handles_labels()\n    # fig.legend(handles, labels)\n    fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n\n    # Display the plot\n    plt.tight_layout(rect=[0, 0, 0.85, 0.95])\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\ndata_before = pd.read_csv(f\"{output_dir}/random_forest/data/results_before_removal.csv\")\ndata_after = pd.read_csv(f\"{output_dir}/random_forest/data/results_after_removal.csv\")\nemb_before = pd.read_csv(f\"{output_dir}/random_forest/emb/results_before_removal.csv\")\nemb_after = pd.read_csv(f\"{output_dir}/random_forest/emb/results_after_removal.csv\")\n\ncompare_results(data_before, data_after, emb_before, emb_after, \"Random Forest\")\n\ndata_before = pd.read_csv(f\"{output_dir}/mlp/data/results_before_removal.csv\")\ndata_after = pd.read_csv(f\"{output_dir}/mlp/data/results_after_removal.csv\")\nemb_before = pd.read_csv(f\"{output_dir}/mlp/emb/results_before_removal.csv\")\nemb_after = pd.read_csv(f\"{output_dir}/mlp/emb/results_after_removal.csv\")\n\ncompare_results(data_before, data_after, emb_before, emb_after, \"MLP\")\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}