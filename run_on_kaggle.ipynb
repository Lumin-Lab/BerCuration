{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8580400,"sourceType":"datasetVersion","datasetId":5131411},{"sourceId":8606225,"sourceType":"datasetVersion","datasetId":5149720}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nwandb_key_label = \"WANDB_KEY\"\nwandb_key= UserSecretsClient().get_secret(wandb_key_label)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:42:42.958359Z","iopub.execute_input":"2024-06-05T15:42:42.959145Z","iopub.status.idle":"2024-06-05T15:42:43.149043Z","shell.execute_reply.started":"2024-06-05T15:42:42.959116Z","shell.execute_reply":"2024-06-05T15:42:43.148301Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import git\ngit.Repo.clone_from('https://github.com/Lumin-Lab/BerCuration', '/kaggle/working/scarf')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:36:11.422171Z","iopub.execute_input":"2024-06-05T16:36:11.423051Z","iopub.status.idle":"2024-06-05T16:36:11.780764Z","shell.execute_reply.started":"2024-06-05T16:36:11.423011Z","shell.execute_reply":"2024-06-05T16:36:11.779812Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"<git.repo.base.Repo '/kaggle/working/scarf/.git'>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -r /kaggle/working/scarf/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:00:28.078314Z","iopub.execute_input":"2024-06-05T16:00:28.078708Z","iopub.status.idle":"2024-06-05T16:00:45.251322Z","shell.execute_reply.started":"2024-06-05T16:00:28.078677Z","shell.execute_reply":"2024-06-05T16:00:45.250169Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==2.3.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 1)) (2.3.0)\nRequirement already satisfied: pandas==2.2.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 2)) (2.2.2)\nRequirement already satisfied: wandb==0.17.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 3)) (0.17.0)\nRequirement already satisfied: scikit-learn==1.5.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 4)) (1.5.0)\nRequirement already satisfied: cleanlab==2.6.5 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 5)) (2.6.5)\nCollecting matplotlib==3.9.0 (from -r /kaggle/working/scarf/requirements.txt (line 6))\n  Using cached matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: python-dotenv==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/scarf/requirements.txt (line 7)) (1.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2.3.0)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.2->-r /kaggle/working/scarf/requirements.txt (line 2)) (2023.4)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (4.2.2)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (2.31.0)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (2.3.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (69.0.3)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r /kaggle/working/scarf/requirements.txt (line 4)) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r /kaggle/working/scarf/requirements.txt (line 4)) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r /kaggle/working/scarf/requirements.txt (line 4)) (3.2.0)\nRequirement already satisfied: tqdm>=4.53.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab==2.6.5->-r /kaggle/working/scarf/requirements.txt (line 5)) (4.66.4)\nRequirement already satisfied: termcolor>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab==2.6.5->-r /kaggle/working/scarf/requirements.txt (line 5)) (2.4.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.9.0->-r /kaggle/working/scarf/requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (12.5.40)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->-r /kaggle/working/scarf/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.17.0->-r /kaggle/working/scarf/requirements.txt (line 3)) (5.0.1)\nUsing cached matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: matplotlib\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.8.4\n    Uninstalling matplotlib-3.8.4:\n      Successfully uninstalled matplotlib-3.8.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires matplotlib<3.9,>=3.2, but you have matplotlib 3.9.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed matplotlib-3.9.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas\ndf = pd.read_csv(\"/kaggle/input/ber-sample/BER_stratified_sample.csv\")\n\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.1, \n                               random_state=42,\n                               stratify=df[['EnergyRating']])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:14:56.232585Z","iopub.execute_input":"2024-06-05T16:14:56.232948Z","iopub.status.idle":"2024-06-05T16:15:00.863984Z","shell.execute_reply.started":"2024-06-05T16:14:56.232919Z","shell.execute_reply":"2024-06-05T16:15:00.863184Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/467251636.py:2: DtypeWarning: Columns (156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/ber-sample/BER_stratified_sample.csv\")\n","output_type":"stream"}]},{"cell_type":"code","source":"output_dir = \"/kaggle/working/output\"\nconfig_dir=\"/kaggle/working/scarf/configs\"\ntrain_data_path = f\"{output_dir}/train.csv\"\ntest_data_path = f\"{output_dir}/test.csv\"\noutlier_removed_train_data_path = f\"{output_dir}/no_outlier_train.csv\"\noutlier_removed_test_data_path = f\"{output_dir}/no_outlier_test.csv\"\nscarf_model_name = \"scarf\"\nmlp_model_name = \"mlp\"\ntrain_embedding_name = \"train\"\ntest_embedding_name = \"test\"","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:13:32.457416Z","iopub.execute_input":"2024-06-05T16:13:32.458191Z","iopub.status.idle":"2024-06-05T16:13:32.463810Z","shell.execute_reply.started":"2024-06-05T16:13:32.458154Z","shell.execute_reply":"2024-06-05T16:13:32.462809Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train['GroundFloorArea_sq_m_'] = train[\"GroundFloorArea(sq m)\"]\ntest['GroundFloorArea_sq_m_'] = test[\"GroundFloorArea(sq m)\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv(train_data_path, index=False)\ntest.to_csv(test_data_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:19:46.698974Z","iopub.execute_input":"2024-06-05T16:19:46.699317Z","iopub.status.idle":"2024-06-05T16:20:04.342503Z","shell.execute_reply.started":"2024-06-05T16:19:46.699292Z","shell.execute_reply":"2024-06-05T16:20:04.341163Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"**Train the SCARF Encoder on the Small Train Dataset**","metadata":{}},{"cell_type":"code","source":"import os\n\"\"\"The trained scarf model is saved in \n/kaggle/working/output/scarf.pt if you run the following command:\n\"\"\"\n\ncommand = f\"\"\"\npython /kaggle/working/scarf/run_scarf.py \\\n  --config_dir={config_dir} \\\n  --output_dir={output_dir} \\\n  --train_data_path={train_data_path}\\\n  --batch_size=32 \\\n  --epochs=1 \\\n  --lr=3e-5 \\\n  --emb_dim=32 \\\n  --encoder_depth=3 \\\n  --model_name={scarf_model_name} \\\n  --corruption_rate=0.3 \\\n  --wandb_project_name='SCARF_Project' \\\n  --wandb_entity='urbancomp' \\\n  --wandb_key='{wandb_key}'\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:20:10.512853Z","iopub.execute_input":"2024-06-05T16:20:10.513613Z","iopub.status.idle":"2024-06-05T16:21:13.268629Z","shell.execute_reply.started":"2024-06-05T16:20:10.513583Z","shell.execute_reply":"2024-06-05T16:21:13.267601Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240605_162014-6bsbjy3n\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run SCARF_Project\nwandb: â­ï¸ View project at https://wandb.ai/urbancomp/Scarf\nwandb: ğŸš€ View run at https://wandb.ai/urbancomp/Scarf/runs/6bsbjy3n\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/1] - Train Loss: 2.188\nModel saved at /kaggle/working/output/scarf.pt\n","output_type":"stream"},{"name":"stderr","text":"wandb: \\ 0.002 MB of 0.019 MB uploaded\nwandb: Run history:\nwandb: encoder_train/train_loss â–ˆâ–ˆâ–†â–†â–…â–„â–„â–ƒâ–„â–„â–…â–„â–…â–ƒâ–‚â–…â–ƒâ–…â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–\nwandb: \nwandb: Run summary:\nwandb: encoder_train/train_loss 3.53319\nwandb: \nwandb: ğŸš€ View run SCARF_Project at: https://wandb.ai/urbancomp/Scarf/runs/6bsbjy3n\nwandb: â­ï¸ View project at: https://wandb.ai/urbancomp/Scarf\nwandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20240605_162014-6bsbjy3n/logs\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Obtain the SCARF embeddings for the Small Train dataset, and save the result**","metadata":{}},{"cell_type":"code","source":"\"\"\"The generated embeddings are saved as a NumPy array in \n/kaggle/working/output/train.npy if you run the following command:\n\"\"\"\nimport os\ncommand = f\"\"\"\npython /kaggle/working/scarf/get_scarf_embedding.py \\\n  --config_dir={config_dir} \\\n  --output_dir={output_dir} \\\n  --data_path={train_data_path} \\\n  --batch_size=32 \\\n  --epochs=1 \\\n  --lr=3e-5 \\\n  --emb_dim=32 \\\n  --encoder_depth=3 \\\n  --model_name={scarf_model_name} \\\n  --corruption_rate=0.3 \\\n  --embedding_save_name=\"train\"\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:21:52.971255Z","iopub.execute_input":"2024-06-05T16:21:52.971632Z","iopub.status.idle":"2024-06-05T16:22:10.293345Z","shell.execute_reply.started":"2024-06-05T16:21:52.971605Z","shell.execute_reply":"2024-06-05T16:22:10.292436Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/output/scarf.pt\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Obtain the SCARF embeddings for the Small Test dataset, and save the result**","metadata":{}},{"cell_type":"code","source":"\"\"\"The generated embeddings are saved as a NumPy array in \n/kaggle/working/output/test.npy if you run the following command:\n\"\"\"\ncommand = f\"\"\"\npython /kaggle/working/scarf/get_scarf_embedding.py \\\n  --config_dir={config_dir} \\\n  --output_dir={output_dir} \\\n  --data_path={test_data_path} \\\n  --batch_size=32 \\\n  --epochs=1 \\\n  --lr=3e-5 \\\n  --emb_dim=32 \\\n  --encoder_depth=3 \\\n  --model_name={scarf_model_name} \\\n  --corruption_rate=0.3 \\\n  --embedding_save_name=\"train\"\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:22:41.297992Z","iopub.execute_input":"2024-06-05T16:22:41.298889Z","iopub.status.idle":"2024-06-05T16:22:51.319931Z","shell.execute_reply.started":"2024-06-05T16:22:41.298853Z","shell.execute_reply":"2024-06-05T16:22:51.318988Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/output/scarf.pt\nModel loaded from /kaggle/working/output/scarf.pt\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Load the training and testing embeddings**","metadata":{}},{"cell_type":"code","source":"from cleanlab import Datalab\nimport numpy as np\ntrain_emb = np.load(f\"{output_dir}/{train_embedding_name}.npy\")\ntest_emb = np.load(f\"{output_dir}/{test_embedding_name}.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:23:42.834866Z","iopub.execute_input":"2024-06-05T16:23:42.835613Z","iopub.status.idle":"2024-06-05T16:23:42.841309Z","shell.execute_reply.started":"2024-06-05T16:23:42.835582Z","shell.execute_reply":"2024-06-05T16:23:42.840420Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from cleanlab.outlier import OutOfDistribution\nood = OutOfDistribution()\nood_train_feature_scores = ood.fit_score(features=train_emb)\nood_train_feature_scores = ood.score(features=train_emb)\nood_test_feature_scores = ood.score(features=test_emb)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:23:45.586815Z","iopub.execute_input":"2024-06-05T16:23:45.587459Z","iopub.status.idle":"2024-06-05T16:23:56.089171Z","shell.execute_reply.started":"2024-06-05T16:23:45.587430Z","shell.execute_reply":"2024-06-05T16:23:56.088334Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Fitting OOD estimator based on provided features ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Obtain the indices of outliers in both the training and test datasets with cleanlab**","metadata":{}},{"cell_type":"code","source":"from cleanlab.rank import find_top_issues\ntop = 100\ntop_train_ood_features_idxs = find_top_issues(quality_scores=ood_train_feature_scores, \n                                              top=top)\ntop_test_ood_features_idxs = find_top_issues(quality_scores=ood_test_feature_scores, \n                                              top=top)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T15:50:05.669499Z","iopub.execute_input":"2024-06-05T15:50:05.669873Z","iopub.status.idle":"2024-06-05T15:50:05.677905Z","shell.execute_reply.started":"2024-06-05T15:50:05.669844Z","shell.execute_reply":"2024-06-05T15:50:05.676874Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data_path","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:24:55.005558Z","iopub.execute_input":"2024-06-05T16:24:55.006486Z","iopub.status.idle":"2024-06-05T16:24:55.012098Z","shell.execute_reply.started":"2024-06-05T16:24:55.006452Z","shell.execute_reply":"2024-06-05T16:24:55.011173Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/output/train.csv'"},"metadata":{}}]},{"cell_type":"markdown","source":"**Remove the outliers from both the training and test datasets, and save the results**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(train_data_path)\ntest_df = pd.read_csv(test_data_path)\ntrain_df_new = train_df.drop(top_train_ood_features_idxs, inplace=False)\ntest_df_new = test_df.drop(top_test_ood_features_idxs, inplace=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:25:11.434962Z","iopub.execute_input":"2024-06-05T16:25:11.435361Z","iopub.status.idle":"2024-06-05T16:25:14.907586Z","shell.execute_reply.started":"2024-06-05T16:25:11.435313Z","shell.execute_reply":"2024-06-05T16:25:14.906557Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2134907574.py:2: DtypeWarning: Columns (145,156,162,167) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_df = pd.read_csv(train_data_path)\n/tmp/ipykernel_34/2134907574.py:3: DtypeWarning: Columns (162) have mixed types. Specify dtype option on import or set low_memory=False.\n  test_df = pd.read_csv(test_data_path)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os \n# if not os.path.exists(\"/kaggle/working/output/\"):\n#     os.mkdir(\"/kaggle/working/output/\")\ntrain_df_new.to_csv(outlier_removed_train_data_path, index=False)\ntest_df_new.to_csv(outlier_removed_test_data_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:26:51.831551Z","iopub.execute_input":"2024-06-05T16:26:51.831946Z","iopub.status.idle":"2024-06-05T16:27:08.980723Z","shell.execute_reply.started":"2024-06-05T16:26:51.831916Z","shell.execute_reply":"2024-06-05T16:27:08.979702Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"**Train the MLP classifier on the datasets, following the removal of outliers**","metadata":{}},{"cell_type":"code","source":"\"\"\"The trained mlp classifier will be save in /kaggle/working/output/mlp.pt \nif you run the following command:\n\"\"\"\nimport os\ncommand = f\"\"\"\npython /kaggle/working/scarf/run_mlp.py \\\n  --config_dir={config_dir} \\\n  --output_dir={output_dir}\\\n  --train_data_path={outlier_removed_train_data_path} \\\n  --test_data_path={outlier_removed_test_data_path} \\\n  --batch_size 32 \\\n  --epochs 1 \\\n  --lr 0.00003 \\\n  --model_name={mlp_model_name} \\\n  --wandb_project_name \"test\" \\\n  --wandb_entity \"urbancomp\" \\\n  --wandb_key {wandb_key} \\\n  --hidden_layer 256 128 64 32 16 \\\n  --dropout 0.1\n\"\"\"\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T16:36:17.154313Z","iopub.execute_input":"2024-06-05T16:36:17.154662Z","iopub.status.idle":"2024-06-05T16:37:34.218666Z","shell.execute_reply.started":"2024-06-05T16:36:17.154632Z","shell.execute_reply":"2024-06-05T16:37:34.217760Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"wandb: Currently logged in as: dan-liu. Use `wandb login --relogin` to force relogin\nwandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\nwandb: Currently logged in as: dan-liu (urbancomp). Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.17.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20240605_163621-kevch2mz\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run test\nwandb: â­ï¸ View project at https://wandb.ai/urbancomp/Scarf-MLP\nwandb: ğŸš€ View run at https://wandb.ai/urbancomp/Scarf-MLP/runs/kevch2mz\n","output_type":"stream"},{"name":"stdout","text":"Model saved at /kaggle/working/output/mlp.pt\nEpoch [1/1] - Train Loss: 1.350, Train Acc: 0.600, Train F1: 0.444, Test Loss: 1.711, Test Acc: 0.349, Test F1: 0.208\nTest Accuracy: 0.349, Test F1: 0.208\n","output_type":"stream"},{"name":"stderr","text":"wandb: \\ 0.114 MB of 0.134 MB uploaded\nwandb: Run history:\nwandb:      test/A1_acc â–\nwandb:      test/A2_acc â–\nwandb:      test/A3_acc â–\nwandb:      test/B1_acc â–\nwandb:      test/B2_acc â–\nwandb:      test/B3_acc â–\nwandb:      test/C1_acc â–\nwandb:      test/C2_acc â–\nwandb:      test/C3_acc â–\nwandb:      test/D1_acc â–\nwandb:      test/D2_acc â–\nwandb:      test/E1_acc â–\nwandb:      test/E2_acc â–\nwandb:       test/F_acc â–\nwandb:       test/G_acc â–\nwandb:    test/test_acc â–\nwandb:     test/test_f1 â–\nwandb:   test/test_loss â–\nwandb:         train/f1 â–â–â–â–â–â–â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–„â–‚â–…â–…â–ˆâ–†â–ƒâ–…â–…â–„â–ƒâ–‡â–„â–„â–†â–…â–ƒâ–†â–‡â–…â–†â–‡â–„â–†â–„â–†â–†â–ˆ\nwandb:  train/train_acc â–‚â–„â–‚â–â–‚â–ƒâ–‚â–…â–ƒâ–ƒâ–‚â–„â–…â–‚â–†â–…â–†â–†â–„â–„â–…â–„â–ƒâ–†â–…â–„â–†â–…â–ƒâ–†â–†â–…â–†â–‡â–„â–‡â–„â–‡â–†â–ˆ\nwandb: train/train_loss â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–†â–„â–„â–ƒâ–„â–…â–ƒâ–â–†â–…â–‚â–ƒâ–ƒâ–‚â–‚â–…â–‚â–â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–â–â–\nwandb: \nwandb: Run summary:\nwandb:      test/A1_acc 0.0\nwandb:      test/A2_acc 0.96881\nwandb:      test/A3_acc 0.1964\nwandb:      test/B1_acc 0.0\nwandb:      test/B2_acc 0.0\nwandb:      test/B3_acc 0.06188\nwandb:      test/C1_acc 0.71779\nwandb:      test/C2_acc 0.48316\nwandb:      test/C3_acc 0.0\nwandb:      test/D1_acc 0.42821\nwandb:      test/D2_acc 0.12169\nwandb:      test/E1_acc 0.08149\nwandb:      test/E2_acc 0.0\nwandb:       test/F_acc 0.01867\nwandb:       test/G_acc 0.97139\nwandb:    test/test_acc 0.34903\nwandb:     test/test_f1 0.20762\nwandb:   test/test_loss 1.7111\nwandb:         train/f1 0.21961\nwandb:  train/train_acc 0.40625\nwandb: train/train_loss 1.66224\nwandb: \nwandb: ğŸš€ View run test at: https://wandb.ai/urbancomp/Scarf-MLP/runs/kevch2mz\nwandb: â­ï¸ View project at: https://wandb.ai/urbancomp/Scarf-MLP\nwandb: Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20240605_163621-kevch2mz/logs\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]}]}